{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG23Og51_lWi"
      },
      "source": [
        "# Emotion recognition- RAVDESS dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP8Dj9Ok_lWm"
      },
      "source": [
        "### Plotting an example for a sound wave:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-SXyFJ9_lWm",
        "outputId": "c390768f-65f4-4251-d75a-62b4dbe2b524"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAEGCAYAAACjGskNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgcZbU/8O/p7lkzk8k22ROSQCCrARIDUZBAAENAIooXUEFBRVTcr1cWRVQQFH7ihuwqKBcuCPeCEhIIAQJCyMKakNWQfd9mJpNZenl/f3S9PdU91VstXd3T38/z5MlMd3X121Xd06dOnTqvKKVARERERES5C/g9ACIiIiKiUsMgmoiIiIgoTwyiiYiIiIjyxCCaiIiIiChPDKKJiIiIiPIU8nsAdgwYMECNGjXK72EQERERUQ+3YsWKfUqpxtTbSzKIHjVqFJYvX+73MIiIiIiohxORzVa3s5yDiIiIiChPDKKJiIiIiPLEIJqIiIiIKE8MoomIiIiI8sQgmoiIiIgoTwyiiYiIiIjyxCCaiIiIiChPDKKJiIiIiPLkShAtIrNFZK2IbBCRayzuFxH5nXH/uyJyYsr9QRF5S0T+6cZ4iMhdjy7dgvtf2ej3MIiIiIqG4yBaRIIA7gRwDoAJAC4RkQkpi50DYKzx70oAd6Xc/20Aq52OhYi88dN/vI+bnuFHlIiISHMjEz0dwAal1EalVCeARwHMTVlmLoCHVNwSAH1EZAgAiMhwAOcCuN+FsRCRB8LRmN9DICIiKipuBNHDAGw1/b7NuC3XZX4D4L8AZPyWFpErRWS5iCzfu3evsxETUVYHWzuxbNMBAEAkpnweTXHZfqgN7eGo38MgIiIfuRFEi8Vtqd+4lsuIyHkA9iilVmR7EqXUvUqpaUqpaY2NjXbGSUR5uO25tfjM3a8nfg8FBI8v34obn16FF1bv9nFk/vvorYtw67Nr/B4GERH5KOTCOrYBGGH6fTiAHTkucyGA80VkDoBqAL1F5G9Kqc+7MC4icsGUnz4HIJ6N/sHf3wUAbNzXilnjB/k5LN8dOtLp9xCIiMhHbmSilwEYKyKjRaQSwMUAnk5Z5mkAlxldOk4G0KSU2qmUulYpNVwpNcp43CIG0ETFIWCcP2pqC3e7L2h1bomIiKiMOM5EK6UiInI1gAUAggD+pJRaJSJXGfffDWAegDkANgA4AuByp89LRN4SyyqsuGCAUbQItwERUTlzo5wDSql5iAfK5tvuNv2sAHwjyzpeAvCSG+MhIucyxckMIOPW7W7BsYPq/R4GERH5gDMWEpGlTIFykEE0djW14+w7Fvs9DCIi8okrmWgi6lkuuud1y1poLcDDb0Ri7J1NRFTOGEQTUTdvfHAg4/0s5yAionLHfBIR5S3AIJqIiMocg2giyhtb3GXuXkJERD0fg2giyluALe6IiKjMMYgmoryxnANQUH4PgYiIfMQgmojyVq4t7lo7IvjqX5f7PQwiIioCDKKJKG/l2uLug32tWLBqt9/DICKiIlCmX4VE5ATLObrEJ2QlIqJywyCaiPJWrjG0+XXr2DnGGJqIqCwxiCaivLG9GxAzomhmoomIyhODaCLKGztTdGWgmYkmIipPDKKJKG97Wzpwz8v/9nsYvtKxc4yZaCKissQgmojytmDVbtzy7Bq/h1Fw5jIWlnEQEZU3BtFERDboDDQz0URE5YlBNBGRDbGY8T9jaCKissQgmogoR0kt7oz/mYkmIipPDKKJiGxQiRZ3Pg+EiIh8wSCaiJLwgrncsE80EVF5YxBNRElGXzvP7yGUBPaJJiIqbwyiiYhylDztdzx63tPSjq0HjnRbduX2Jjy+fGuhhkZERAXGIJqIyAadgL743iU49VcvAgDW727BvzbsAwD8cv4a/ODv7/o0OiIi8lrI7wEQEZUK82QrG/e2AgAOHQknbvvmI29hza4W/OPqU1AZZI6CiKgnYxBNRJQjhcwF0Poaw0/84dUCjIaIiPzEVAkRUY70BCvpZAuyiYio52AQTUQJMbaayCjXTDQAhAKSfkEiIip5DKKJKCHKnscZZds85rsjPCAhIurRGEQTUUK+U1hf++R7bONm2H+4gxOvEBGVEQbRRJSQreY31SNLt+Bvb2xxdQzRmMKyTQdcXadbMh1kTL1pYdlNAd7UFkY0ptDWGUVnJIabn3nf7yERERUMg2giSrBTzuF25e/L6/bgM3e/7vJa3ZFPOUc5mPLT53Dv4o0Yf8N8vPbvfbjvlQ/8HhIRUcEwiCaihKiNOl63r5+LRIs3FM02MqtyjlueXe3NYIrEtoPx2Rp1v+z3tjX5ORwiooJhEE1ECXa6cwTE3Si6eENo6yA5+f7utz399g6PRlMcdIlLezgKAPjtC+uwcjsDaSLq+RhEE1GCnXIOt4PoYpbtGMNq+/X0Lh367MWRzngQvXD1Hpz3e042Q0Q9H4NoIkqwk4n2Kob++T/fxx8Wrfdm5Tb8YdF6rNnVnHEZqwsPe/rFhlHjYtQjnZGk2w+0drJbCRH1aJz2m4gSbF1Y6FEQ/cCrH6ChpgL3LN6Imy+YjPOnDPXmiXJ0+3PrMKCuMuMy1t1NenYgqQ8cDrSGk24/69cvo746hJd+cLofwyIi8hwz0USUYO/CQpdrolOG0NIewbtbD7n6HHbtO9yZ8X6rTHRPrOaIRGNoaY8HzbpcZcOeFgDA0IZqAMD+1k5s2n/EnwESERUAM9FElJBvn2igMDXRFaHSON63OgjJdwKbUnDbc2txz8sbAXSVAHVE4m+e1E2w9cARHGjtxJQRfQo6RiIir5XGNxMRFURnNP8o2ssYWq+7Ilgaf6osM9E9MBX94po9iZ/1gYPOSKdug4vvXYK5d/6rcIMjIioQV76ZRGS2iKwVkQ0ico3F/SIivzPuf1dETjRuHyEiL4rIahFZJSLfdmM8RGSPblOWDy8z0XrNlcHS6ABiFS97HULbKcFxat3uw4mfI8bpi840mei9LR0FGxcRUSE5DqJFJAjgTgDnAJgA4BIRmZCy2DkAxhr/rgRwl3F7BMD3lVLjAZwM4BsWjyWiArEXRHswkBSlnIn2uprj6OvmYfXOZnywr9XbJ0qjzXjP6LMY4ZSzGcFCvEGIiHzgxjfTdAAblFIblVKdAB4FMDdlmbkAHlJxSwD0EZEhSqmdSqk3AUAp1QJgNYBhLoyJiGxos5mJ9qqVmRhZ7mBA8I93in/SEusg2vtM8e0L1uL021/y/Hm0oOnsQ2tH/D0TNjLRqa+XQTQR9VRuBNHDAGw1/b4N3QPhrMuIyCgAJwB4w+pJRORKEVkuIsv37t3rcMhEZKWtM/8g+q2thzD62nkujqJ70LlxXyu++chbLj6HN6wuzCxEtUVLRyT7Qi4KmL45DhvPrWuiU88aMIYmop7KjSDa6k9k6tdGxmVEpA7AEwC+o5SynM1AKXWvUmqaUmpaY2Oj7cESUXq6w0I+mtrC2RdyqKpEunNYZfJ7YncOc3a51QiidW32/tbkNoABY9nfLlyPf75b/GcTiIhy5cY30zYAI0y/DweQ+pcy7TIiUoF4AP2wUupJF8ZDRDbc/8pGW9nehpoKD0YT1xGJB6WlHIcWYuiFTvaaLybV031HUmqhR/StAdA1tjsWrsNvFxbPDJRERE65EUQvAzBWREaLSCWAiwE8nbLM0wAuM7p0nAygSSm1U+IFjw8AWK2U+rULYyEim17/935bj+tVGQTQPYhygy4v8aMDhVt64tTX5ky07soRSdlHVn2jC9FTnIioUBwH0UqpCICrASxA/MLAx5RSq0TkKhG5ylhsHoCNADYAuA/A143bPwrgUgBniMjbxr85TsdERPmzG9/owCg1iHKDXqUX6y6UcFRh3ns7XV/va//eh1fWx68PKVRs2h6OojMSQ6Wp7lm3uIsplVT/rLt1mA8iNh9oLekDIiIiM1dmLFRKzUM8UDbfdrfpZwXgGxaPexWFPxNJRJZsfhSNh7lR+7tye5NlXbYXWe5CuuGpVZgzeYir67ziL8vQHs6+Xdo6o2jpCGNgfbXj5zzz1y9jTGNd0sWDkahK/C8Q6AKWQ0fitfLmmLk9HMNjy7fikukjHY+FiMhvpXG1DhF5zm42Uz/MjWzxeb9/FY8v39btdr3uUi2NiNqZTz2LmopgTstd8+S7mH7zC64857aDbVj2wQGETJPf6D0SiSnL47DDKZ1DDrR2duslXaoOtnbiJ0+t9HsYROQTBtFElJN0MbY+Pe/W9NZWnTjSzYZXKrwoR6mtzO1E4p7m+IyBG/a0YNvBI46eMyiStpd4NKZyOpdx24K1+MbDbzoah51JgbywZON+PPj6Zr+HQUQ+YRBNRACyF3OkCwPDxul8t2pd66q7B4e6S0ep1tN6Me4KUzY40+r1RYBn/noxPnvfG3jo9U22g+lhRscNqzMCkTyy7at3WXYyzdm4H8/Hhj0tOPHnz+NIZ2F7ZGvrdrcUrBadiIoTg2giAmC/nEOfmncaKGbKZOtM7i/mrca3CjzpyraDR3D0dc4mk/EiiDavUm+79nAUhzsi2NPcngh0zbXq4WgMNzy1Cn+1mT0d0qe623NbjSeboAvR586mdhxo7UzUXhfKojW7oZTC2XcsRqdxALn1wBGMuuaZgo6DiPzHIJqIHEkE0Q7rlXU3B32hmpkOQuev3IWnCzz99wf7nHeU8KZzSdc69ba//M/LcMbtL2H6L17AvzbEWxZ2mEofnNavh4ys9s6mdluP19xsdVeobPD3H3sHO5vacMVflidKWvSBygf7WgszCCIqKgyiiciRTpcy0Xo9Vt059LqtSj1KgTeZ6K516kz0ko37saclXgOtyz2sntrueLIFv7kGtAEHc4Hr16pfghSowdMTb27Da8aBSWKq85QDPqUU3t+RXKryq/lr8L3/ebsgYySiwmIQTUQA7AcjuibaaQMKffFgp6lzg461utqoFb6rQ6GCtHyZt3eiewm6aqD1hYfKXM1uvJRoTOHOFzckas1zFXQQ/Catx0H6WGfd/Xgv6C3Z2hHfbvpARr+c97Y3Yc7vXkl6zKPLtuLJt7YXaohEVEAMookIgP3T4jqrmc+FZVZ0WUinKbCrCgWT1l2qFxZ6IamcI9b955hKztgCXdOnR2IKty1Yi5Xbm/J6TjdqmQFnmWj9+vRBl9MyonzobdpqZKITQbRxdBK2KEU60NpZoNERUaExiCYiVzidbCWRiTaVc+iSBB04hYsgiC6WvHRSOYfFtte3mTtp6LHrkogDrfldlGeOoZ1sh6CDB+vXlZhW3MP3xPgfz8fWA12dTFRKEK2T4Xq7sFsHUXlhEE1EAJwHAE7PrluVc0jKlOJeBkw5y7KdChFH7WxqgzlutsrQ65uSMtHG/3p75tsezrwuJ+8XcfBgPfbvGHXGbl20+bn7l+ArDy1Puq0tHE26aFBv8840F9MyhiYqLwyiiQhAcu2vnWDA6WnrDotMdFNbPFMacbkXtRN2A6XUmfucmHHLIuw3be9OiyMYlchEd92mx96VOc3v1Zi3v5MOG05Kq1MPpNx6T/xrw368tHZPt9vNdeD6qTpTsuB6Cb1Nmo6E2fKOqAwwiCaibuyEJZfct8RRoKiDaKu6Ul0T7UWrOLelG2FLu3f9jJsseiWv33MYo655Jilbqn+SlP9zZS4bMcfQdVX5dU1xcoFiatDstIzIat3rdrdgx6E2APFttHjd3qTnStRjm5Y3azUy/F7ucyLyX2n2iyIi97lwLrqtM5p3QAUAD72+Cb+avxYA0NzWPfBIvViukFITrnaH4GZv5FTN7d0PXq598j0AyZnbimA8b6Iz1/mOKd32z/el1VYG83uASWoJhZtnJ/Sqzr5jceI2BeCyPy1N/Ax0bT+9PW78x/sAug7y9AFhoSeCIaLCYiaaiAC4U89pt0PHvYs3JrLY+y3KQnRwUuhyjoXv78Z//f3dpNvsjsCtENpqym0rZ4wbCCB5mw1tiM84+NTb9iasybZ7cz3A0O333BiD0/dEa0cEm/e3pt0/yzYdSPyst/23H43XYz/3/m7LsbQbk7FY9Twnop6DQTQRAXAnU9oRthc0bDvYlvF+vzLRjy7biu2HMo8tV/+9dIsrvY2t6p+t6L1pztyGUtpiKCjsbMr99aVrJ5fvbqlxORN96QNvJDpm5Oun/1iF0257KdF2760tB5Pu/83C9Ymfb3hqVdJ9Sz84kPT7f9zzOgAkZjT8+sMrEvet2HwQuxzO9EhExYVBNBEBcGcijUeXbc26TD5Bm6aD80Jnot2swPjNwvVYt/uw4/V05pjdTJQcmLZZ6uaLxhRm3LIIa3bFZ9kLR2P4yVMr067TvC5z7bo+i5Dr3qkK2f/qiabUzEeVwivr92U9EEtHl1zoHtgX/PE122PTdEBv3t+fvus1/PCJd9M9hIhKEINoIgLgrGOC9sCrGzPev/9wB2bcsijv9R4J68ktbA3LNvMmcWP7rNh8IPtCWeQaRIct2rCFU7LYiZZtxjp3HGrDg69vRmtHxLK7RNbtn+P+sbsb3912qNssi58ygl67B1j6YalZeicufWCp5e0uTfhIREWCQTQRAQCWbz6YfaEswlGFR5duSXu/Duh0RnOTqQdvJu1h+xNrvLJ+L7732Nt5Py5VdYX9EgTtx0+twpf+ssxRF5Ns5Rw6TrOajr0l5QLEW55dDSB+FmLh+7sTWdl/703OmB9s7cSMW17oFoTnq9K4sNFuv+/z//AvPLLU+myH/bMU8cf1rvb+OvtgQNARidouPSGi4sIgmogAAJv3H8m+UA5+v2hD2vt0oPP6xv3YvL8VM29/Cb+avyZxfyhLqs5OmPT3Fdvw5JvbbTwyuU7crYleXlizJ2kWvHy1Z6k710MOR5I7SABdfbe13c0dAIC9LR348kPLE8F9a0c826v31/ZDbdjZ1J41+FdZ9pC+/4k3t2PJxv0Zl00nXQAatnlRq9489dUVth6fj4Wr9+BTf3wNJ/78efxrwz7ctzjzmRsiKm4MoonIVZlqq8OReMTyufvfwDcfeQsA8MeX/l2QcdlhronucOGiQM3JRZy680M6iQlBLMo50gXBegkdZLcbJRO624rOQH+Q45mDdMzXBC7fZK+0pT1i/fqzbZd09EGGm+Uc2vEj+nS7bdWOZnREYvjR/63EzfNWu/6cRFQ4DKKJCAAwxGh/5lSmINpcipBaWuAV91rLOV/H5GENAJzVxuYaLKbOqgek3+ZHjMyz7h7REU7OROc6yU0+2ygYsPf1k+71t3XaC6K7JqDpvlOqK5x9RR402jVanWFxekBCRP5jEE1EALpfdGZXpgDR/BxWQYQfk6lk4vb8KDqwdfIqs5VzJJ7LIhOdzvs7mwAAzcYMe7pFmw6ec31v5HPdYbbSnXTSvf5ct0uqTJvHadvHzQeOoDIYyHhg6UbbQyLyB4NoIgKQe//hbCIW03Zr2YKxXGPodbtbcp50RBwEQlbZSSd0cOrkgCXXTHQ40eIu+7J3vhgvqdl5qN14DiMAN/Zlpn2q5bKlzPvMbkvFtnSZaIflHFYTBR2xmd02CwQyT7rS6sJzEJE/GEQTeUwphRfX7PF7GFnlEijlYuvB9BfNZQ2ic3yOs+9YjNHXzstjVDa5nInWAbDdbb39UBsu/8uynJbVz5GuDtoqE/w/y+OdL3RpRCSWPsBMlcsrMleF2K1BTp3gRGvrtFcelNrmz8yNMxHZstmtHZGcDwiJqLgwiCbyWFNbOOfAx09uBdEfG9uY9r7OiH/BgpOOGG7RGUm7megdecyeaDV9ulmmPTF/1S4AXTXRYZfeG2ZOzhBYcZqJtqwXN73sYJ7j7WXMypjtUZv2t2L0tfPw9tZDea2fiPzHIJqIADibDdAcX/Svq8Qpv1yE0257MWlijAde/QC3P7fWyRC7yaff7j2L8+8C4na/Bt39wm5QareO2FKGIehsr85Au3WApVUEBXVV9vtuV1hkse2WXuizA5kOOgS51ZZ3exCyHywsXrcPALBx72Hsbm7HvsPxtoPpziAcOtKJv6/Ylt9YiMgTDKKJCIc7IvkHCSbmhy5cvQfbDrZh8/4jWLR6D9btbgEA/GbhOqxwYUIXs1N/9WLOy9o5SHh53d68H5OLXMojrIRsdrSwkq2nM2DORLt78VtFIIAdh9qx3wgYc5FtpsbmlB7Y2TQZE8vsbck+BvOWyvk4xnhQtsX/+e4OAMD+w504+47FmHbTQmzcexiTfrLAsjf531dsw38+/k6OgyAiLzGIJvKY/h50a7IOL3zfhRn9NPOEHl97+E2c9/tXATjvdGDlQJaSBaAriLETRHvVhs9uUOrkQMcOXROdOtW2UwrAbQvW4qJ7l+T8mEVrdid+ttqVerbFXLy2YR+m/Ow5AMAeiyA60zs12y7o9jYX68y5pt9jndFY4rOjSzseePUDKKWSaqbdLoMhIvsYRBN5TAdvhQ6AtLe3HsLXH16RcZlN+zysF1bAM+/u7DZbXqE9tnwbdjblXlPs5cVedksP3MwI5/Lqnn47niV9a4u79bp62+YS+Cql8NN/rMJVf3vTfGO35XR7vlzsNWXAM3XOsBxPlvv1waJ5uUxvJf25MGfadWC/aX8rvvrXFfjUXa8l7vNgThgisolBNJHH9IVLTmqOnfjHOzsw771dGTPhB49kz+jaJQJ885E3sy9oU9Zg1xR03PPyRqzZ1YzbFqxJv7zBi4vptMM2M9w6iDYnI23HVKaXl65E4bcvrAfgfkZeP3UuNd4dkRj+/K9NAICaimDS483MB2mb9rXitwvXp12n/kx+9a/LM47PzjtAvx+7/s+t/7n5IEBPehMKCJZs3I+3thyCUgptnVEE3KyLJyJHGEQTeSyRifYpiNbPO+3mhWmXsdvZIBeRmLI8/e6WfNb99tZDuPulfyf6ImfidgmDmd2gVAf25jDK63fVa//e5/r7w9yb2XwQ1GKRTTZn36OmwDSVDqLX7W7BQ69vxh0L12GTaUKffabssy5JX7Bqt+sT6uix6f+jsVhO+0gfKPSqDGJPS3vidt1P+4k3t2P8DfMTme5iLg8jKhcMook85nc5hw5CDrR2Yv7KnRmX8YLXBw/ZLtIzT5iy5cAR/J9RopCO7viR7UI2Jw7ZLG3Rs9u5sUlzXUVzWzjnCV5ypd8T+w534m9LNuONjfux9IMDmHzjc9iw53DSsuYzAjpwtBp7c1sE4WgMZ9+xGI8s3QIAmHn7S9i49zDW7GrGtJsWWn4W3f5Y6tXpd09bOJbzc1SFAojElKk7isJBo+RlvXGBrg6iF5VA73mino5BNJHH9BeoX5mjh9/Ykvh5S5peyV4GjF5bub0552WzXYi49IMDmPiTBVix+QAWrNqdcVknHl++FW9uOYgrH7IuJ0jnSw/mt3yuMr0zaytDtqfUTsf8UXjg1Q9w0b1L8Nn74hcZ7mlpx/Pvd2178wFeprKIlvYwxl7/LABgYO+qxO1n/L+X8ZRx4LSrub3bOj1j4+PeEYmhMxrDvsPx96n5jMU9izcC6Cq9YR6ayH8Mook8Fk2cuvb/a+8X85JrgXWLsSIYmm2fvus1XPGXZdi8v+vU/eJ1e9P22dXW7opPHW4uIdAlHJ++63Vc97/veTNgxC8c+9QfX8NzpmCxIxLFe9uaXFl/3hUKafZ/fVUIu5vb8eYWd1sTmm3aHz+w05+Pz973Br5iHFwopZIO8DK9T80lJ5v3Jx8s6gsYr3syvk8LcdCYSx20FfPDzAcTXeuN/68z9tGYwsrt7rxviCg/DKKJPKZPIfuRiTbXVmpRU9uyqTctdP1UvR8WrdmDxUZP5x/+/V1c9qelePa9eOmKuR9yVajrT97Hf7MYT7+zA5NvfC5xWz6Tt7hFdwy55+WN+MQfXnVlnfm+09ItrwA8vtyfiT0m37gAo6+dl3aa71SZPl66vGPysAYAxR1Em1nVouuDu1/Ojx8Q/+6F9Yk2kkRUWAyiiTyW6M7hQ030gpW7ut129HXzcN7vX8FxP5oPANh2sHDTYec7dXI+jnRG0dIexv8s3woA6FtbiXA0lhQwpbYz+/aj8f7YD72+CUC8d3GhzbhlEQ62duJe43T99f/7Hl7bsM9y2bqqUCGHBqUUlm7KLYh1my5l+L6LE4scOtKJn/9jFW55Nnt3FqcKccw8f+XORAcVIio8BtFEHvOzO0drmn7E5jri/35ja6GG4+mBxJKN+5PKIX63aD3GXv8sRvXvlfWxNzy1Cnua230ruTnh588nyk8efmMLPnv/G/jXhn34UUpJSUFqeU1KuczHyvs7m/GA0QWjJzD3zo7FVI84q0RUSgqb1iAqQ13lHIV/7tYcWqk9vqJwQbSXXly7Fy+u7Zqme/3ueM3o6p25XXg4/RcveDIuuz53/xsAgJsumAyge31wIXjZ5s8Pb7o8aUwxGXPdPADA01d/FH1rKzGiX63PIyLq+RhEE3lMl3Os2dWMkf0L+8V2uNM6iA4FBJGYQjAgnk1t7TddT/pCEbcCC0j3bG/qbVsPHEFTWxjPrdpV8I4MPS0TXQ7O/8O/MKJvDV754Rl+D4Wox3OlnENEZovIWhHZICLXWNwvIvI74/53ReTEXB9LVEpeXLOnW9mG/v3Kv2aeetsL6WbGi5hKTCpDPbeqq9gnd7MKUlNv+/FTK3He71/F7xZtKMygqOTtbGrH7QvW4luPvIUv/GkpRl3zDP7TxdpyIopznIkWkSCAOwGcBWAbgGUi8rRS6n3TYucAGGv8OwnAXQBOyvGxRCXj8r8sw1Pf+CimjOiTuM18lX57OIpITKEjHEX/uiqrVbjqSJqaaLNS7hFdDl4ylagQ5SISU/jDi8kHXX9fsQ3nTBqMVdubMfeEoagIBtDSHsHA+iqIAA01FRAPL/wl6oncKOeYDmCDUmojAIjIowDmAjAHwnMBPKTi87suEZE+IjIEwKgcHlu0lFL8o9PDxGIKASN9qacj7ozGUBUKJi3XEYlCqXhP15rKIGIxlej88OzKXRg3pB6hQADBgKDZlA0e9+P5iZ9njRuIhtoKTBragMb6KuxubseQhhoMbqjC8L61iMQUDrdHMKJfDZQCKkMB7DjUho5IDO9ta8KkYQ0IBQX11SEcbsM6y8gAACAASURBVI+gsb4Kh46Ecf8rG7FqRzNuumASFq72bsKQUtBTyhEEnFyDcpPpvaIn6/n1wnWW9w/tU40dh7raYp4/ZSiefmcHfjZ3IiYZ7QEPHenEuMG98fbWQ5h6VF8IgNW7WhKJgUG9q9C3thKdkRiqK4JoD0fRUFOBcCyGSFShtSOCqlAQwaCgKhRAQARNbWH0qakAAAQCgmhMYfP+VvSprURbOIoBdZWoCAQQU/ESNP29G4nGEAoG0B6OIhpTqAoF0BGJoZfRxUYpBaWQ+JsOxM++dUSiqAzGZ4esrggmbg8GJOl7PRZTEEHG73m9vDLNB1ARzH52LxZTiCmFgAgCKc+bKhyNIWR6DSKSaJl6JBxFTUUQkVgMFYH46w8FBTGlun1v5cv8fagpU1JIj1ff5iQeKtV4SpTDq+VF5EIAs5VSXzZ+vxTASUqpq03L/BPArUqpV43fXwDwQ8SD6IyPNa3jSgBXAkCwd+PU4V/7s6NxExERERFls/2+q1rC+7f2Tr3djUy01aFDamSebplcHhu/Ual7AdwLAFNOmKqe+N5pGQeVfFQTPxo1H+V0P5rSy8ByWTEu9hF0LRNVKqnvbfzH5OfUokohFAgk1md+8cmPg+Xj9TpS++x2P3Lreh1d47de1vrIz/z47vcZa8rw+O7rNh+pm4/YrfZHTHXVsZofY73+1LGkjlkhGotPthFKZJeT16P3pUJX2YUY69BP2xmJISCCULBrHZ2RGJSxrWoqg4gphbbOKC7442s4dewAfPesY1FTEUQoIHh53V7c9Mzqbq9hYH0VBvWuxqRhvdFYV4Vdze0Y0lCNoX1qMKxPLaJK4WBrJ0YP6JXIwOxp7kBHJIblmw9g2lH9Eqdhm9vCGNRQjYOtnfj9og1Yub0Jv7n4eFz9329Z7h8qLcxEkx+GNlRjR1M7Lpo2AtNG9UU0prCjqR3jBtfjna2HcNKYfqgIBrBu92EcONyBxvoq1FaGMKJfLSKxGGoqglAAggFBQAQd4SjaIzFUBATBgKC6IoioUghHYuhdU5HIBkdjCtsPtaFXZQiRWPy+ymD8zB4ABCS+jL6moyMSRUckhqpQAOGoQu/qEKKq67ssElWJMSgodIRjqAwF0BaOoq4qBEH8jGNFMIBoLP59EVNAJBYzMtxBBER/jyd/l+jHCeJZaP23OigChfj3Wdh4fqDrG6rTaFcpkMR3jUj8dwWVeI0BEURi8e+geKYcRjwSf/3hqEJFMH57MCDojMQgEt9GlaFA4m+HMr5bI7H4dqkIxp83ElNJY9BjjCkkxmG+TY9T7ytBfLsERBLxkY6VYHruYMBYp9KvM32gaI4dYsbrMsdNqd/1yfGcvk+ZYp/k5c2PSY5q0sU+wNhfbrNsyO5GEL0NwAjT78MB7MhxmcocHttNRVBwzMA6W4Ml8tp3zjwWJ47sm/i92TSt9NLrZmFnUzsqQwGMH9LtoDZn535oSNr7PnrMgERw/8y7O/GsxYQr5UIfJJW6HvASioJVN5Ry8sPZ4/Di2j344kdGQRDvI3/coHpUhASD6qvRpzZeF90ZiSUuOE6XyJgzuetv0KljG10fqy4fISoSln853AiilwEYKyKjAWwHcDGAz6Ys8zSAq42a55MANCmldorI3hweS1QyvnPmWEwcmhwcB0xfQAN7V2Ng72pPx6Br/AAkagMzqQgKwtGeGVmUcgZXZ+QG1FVi3+FOv4fTI5RTAP2h4Q141zT50PTR/XDVaWPwtZlHZ32suWNPKdapEhWK4yBaKRURkasBLAAQBPAnpdQqEbnKuP9uAPMAzAGwAcARAJdneqzTMRH55TtnHtvtNn0a7yefmFDo4aBXpfWFJUGRxKnJcFT12AxdKb6mRLmYMfg/f3E6djW3484XN+DtrT13shByT+/qEJ6++hQA8UyyPkhmQEzkLlcmW1FKzUM8UDbfdrfpZwXgG7k+lqgn0ZnoM8YNLPhzp2aidWZWT7+t+0WXYrCZTX11CC3tEZw8ph+WbDzQ7f5MBw5+ZrBTy08mD2/AZDRg1riBiVnpCqWUM/nl6r7LpmFQ7672mSKCyhCDZyIv9NxZFoiKhPlimEKrq04Ooq0CostmHFWYwXisf69K3HHRlMTvvavjLbNOGNHXcvnUAPrvV83AKGNGyWIIHG84b0LStR+BgKAyh9ZZbqqq6FlfERMdXIdQ7Fb86EzM/86pOGvCIHxoeJ/sDyAix3rWX0iiIqSD52Cg8EF0TUX2PqFzjx9WgJHEebkJvnzqGJx+XFe2//pzx2Pp9bOwq7k9w6Pizpk0GNNG9ctpchovPPfdjyV+7l0dwg9nH4crThmNhSldiAod1KZ2Ayp1k4Y3YHCDt9ckFNIPPn5c4uf+dVUYN7jnHiQQFSMG0UQe08nDkA9B9MzjupeQrL/5HGy69Vws/sHpAIBxg+sLNh4vy0ZqK4NoqKlA39p4Brq1I4KB9dVJZwBSM7k3fXISAOCuz08FAFw7Z5x3A0zjn988BccOqseVHxsDAHj3xo/jazOPsVy2Jc007l4RAU4Y6W9W8/Mnj3RtXYPqq7Dk2lm45hzv93MhPu3fOP0YfGLK0AI8ExFZcaUmmojS00Fc6sxPhTB6QK9ut+nZtEb2r8XTV380pw4exa66IoATR/aFiOCtG87GXS/9Gx87tnvbLd2bFQBu/dRkfHrqcJw8pn/itv69vJ+KPZVu5fWNmcfgRJ8D1lQCwbmTh+CtLYW/oHHTreei6UgYTW1h/G3JlqzLZ6pxv2T6CDyydCuWborXxheiLCYYkMQ1B3ZVhgLojMSSbvv5Jyfhx/+3Ep86IX4G6bYLP4TZEwc7eh4isoeZaCKP6TKOYjg1/qNzxyf9rmsnfYjvXXPzBZOw5ufnYPLwrr6yX5t5NAZlaSV48fSRqAgGkuqOdcjz0BXTE0GKV+6/bFoiaw4ADbUVmD0pff9vL6V7a7Z0RHDsoHqcMML74F6fqbn78yfiG6fH27A11FYktVvL9D41T3Fcn3ItgL7vxvMnAkhu4eYVNz7up1kcCFYakz7pXvHVFcGMfeOJyDsMook85mcmGgAu/nDXfEapwYUWKvAFa2769InDM96vTJcJpmv5p516zAA8+fWP4NSxA3BdygGHm646bQzOnDAIb91wdl6Pu/+yaZ6MJ9M7sy0cRVUOtfV2n++7Zx6Lmy+YhJ/NjZfWDO9bix98vKvcoiJonhU2/Ujrq0N4+4azAAAd4a7s7UNXTMcnpsSDzKMb4wdMBQmibRR0VAYFlUFJfE4b67vOjHzl1NEAAH0ypT0c6/Z4Iiqs0j+PS1TkdCbaj5poAKgyBQwXTh1huUxlsPtp41KRz3Yd3dgLQxtq8Nz7uy3vDwQkMdukl4FW39pKW4/TU88XcibGgAhqXL6gMWRM8CMCfP30oxMlRtNG9cXYlNloK0z7ISiCaJreKfXVIfSprcSDV0zH/JU78cjSrXj0ypNx8pj+iMUUnvjajMTzmM8K6Ult3KLbAuq3ZWUwgHA0llPHl86oQm1lECeN7oeFq/cgFBCEjLIQfWYlZuz4syYMcm3MRGRP6aafiEpEopzDpyA6GIh/zN/5ydlpx+Bl14fKUMCVU9vpZN2upuhl3ODeuHTGUTh5dL+s6/Wybja19WCurMZkd9Pm+rgzxw/MqctLPvTZmUG9qxOBLQAcO6i+W7bZ/Jr1vrZ6P/WpiR+YnHZsIy6cOgKnHDMgUe8eCAimHtW1z42PBIY0VLsaQCeNTQfROb7/L5oWP6PSEYlhaJ+axCr0NQtf/MgoLP7B6YkguhDZdCLKjJ9CIo8lyjl8qon+6DH9MbC+Cg01FWmXsZsZzYmKn7L3Sj6zsH3l1DE4dWwjHv3qjKzLehlE11en3xeZ6LIbt7PQ6eLI8z40BCKCmixlMPnSeyyXALYyGMBQoy1dWzia9Hiz3jVdByZTj+qLv335pLTr1J/F16+dlduA86DLOPRzCHL77OtMczSmMNAo44gqhVH9azGodxVCwQBG9q9FrCfOjERUohhEE3nM70z0rPGDsPT6MzMu06+Xd0G0gsK3Zo3NGMQXwn9MG47j8mjn52UNe7ba7HTM9cGa3ZAql2MPPY39CSOtJ6yxSx/45BIQBgKC166dhR+fN6Hb483yeX+ZM+tW5UApyWTL+9JLeU2SeVvr+mdzZlnXQjfUVOC/v3JyUr/wKGNooqLBIJrIY/r7s5g7YPzu4hM8We/3zzoWv7/kRABdtZx+8esgxkqFzSx3KFDYP9k6wKxzuQ2iCPClU0bj8auynxHQLjJdIGu1K/MJos8cPwjPfvtUAMkX72mZ3qnZDj50kJtYTAGRDJFvvbFtze+JiUPjnWa+NWsselWFks5cKJ8/R0TUhUE0UYHkU3ZQaIMbql0L8s2t4a44ZTRmT4r3sD1/ytBEwOCW1645I+dl7QTRXk1kEbLIKOci6mIAlUv3iMRFsTbHm45SCpOG9caYxrrsCxvMgbzTTHQgIBhvTAE+0CKIziTnagpjiAqZg3Ldz7xvbSXmfetULPzeaZg4tDee/+7Hktr2aWeOH4TPTM3ckYaICoNBNBEBcC9T2xmNYd1N5+CDW+YkTeRy8wWTcc9lU115Dk1fgJWJDmCytcKzfKzLWT+9je3WW0eiLnZQyVRiYOw3HTy7nQFvC8ccTbFu1UnG7qRBtZUh4/GZS2zsfjyyvYc+bkyUMrxfDSYM7Y1jBtZBRDB2kHXp0agBvXDbZ6bYGwwRuYpBNJHHetdU4MunjPZ7GFnZLTFI9cx7O42OBN2jjkLMFJeOnbpet8+c69pzu325++RxAah5IhcrmWLCb585FkBX0G9Vi+2U2xfI2b34Ub/GAXUWGWnTy853uK0d8YOEbA8bO6gOr197Bk4e3T/LkkRUbBhEE3ksGBD8yHRRVLFyq4/1kIb0MwW6Fag/8IVpWH/zOTktW0w1pNVGK0G72/qYgXU5T7iit3W6emar0hBdWqAD0gojA+3WZDzmlx22eYXc9FHW7Qmrbbbh08d6Vgd4brx1sl0LUFcVwpCGGt8mYyIi+xhEExEA9wLcTD2Fsz1HrnHErPGDXBtvJsp27wtrets4GXttjhlX/RzpKjHMsZ2uYz/emDq92qjFDRoZ6AqXAjzz2Qm7/ZnT9TS328taj8kq217tQv/0mEqe8CiV3TIUIvIfg2giAuBeEJ0pNqoMdQUqI/p1r2cutosv3U5i6zZmTmLSXKfg1s8VzGGbnj5uIICu/tU6Ex1KXFiY23sjn5cVsRlEp8s42w2iE/vCYjvlsu0yCQUESmU+FCvEwSAReYOfXiICAOxqbndlPZkyjOaAoa6qe81ucYXQ7gfRK7c3A8i/vtYs12BRlyeYD0zSXTynSz4G9o7XBesMbL7dObLFnOa7ozF7F0mme/12a6L1mJTFTml1cPEjEJ/GPBxVlhdCDqjzcIIjIioIBtFE5Kpcgujr54zHDUad+EyjDhfIbQKQfLkVB2c6JZ8vJz2zs5UY6MxqhZH1N2dT09VH63pcfeGjzvbqrhy6NnpU/1qbo44z796j82hvZ5ZuP9gtvdCzCbrZPlBbsvFAt9v0PvjBx4/D3OO9aaFIRIXBYiwiclWm3so6o3nFKaMREOAvl38YM48biFHXPAPA/sVmmZw6thHvbW+y9VjziXi3WgAGpGuKZztyvYCu0qImuqGmArubO7ot26+2Eld+bEwiwNPZXv2S9YQkjut3jfV9+sRhOGfyEFurqEgTRFcGnV1YeLgjYuvx+Thz/EDc/pkpONwRwfC+tbjowyM9f04i8g4z0UQEIB7YONWrMohrzhmXfgEjJg0GBCKCmccNzGm9VQ5qiS+cOhyLvj8z/wciuZzDbg2v2VWnHY2Nt5zraJr1yiwZcT1MnfU3Z6J7VyeX0PzmouMTP183Z3yihd6YAfEssS4FGdxQjU23nps1G59tAhd9liJg85TDby8+HhdNG2F5n/1W1vGxNLd5H0RHYwp9aisxvK+zjD4RFQcG0UQEwFmdrnbacY0Z72+sr8JjX819qmdNd6Qo9NTd5k1iVdear3NtZl/NsgXRqcuZW6elZnF1LKsz7kMaqjG0TzUaaiuw9qbZ3daZNfjNcrd+j9lt5zb3+GHom9Ir+8mvfwSA/Qlh9FA6XZzI5i+Xf9jydg9OtBCRjxhEExEA+y3HzH7w8QxZaMQzm9NHW/f5zaSrq0WBg2gXg54PDWvAMQPt1QGb5TphTaLFnWmbpT4yIILHr5qBycOM1nYVQbx2zSwAsJxyOikgN11sqC9YzHXvdITtB6ypsbLOtA/qnd/03Yn1GY/Xk7/c7sJsgLrLiXkb/XzuRHzvrGMdr5uIigeDaCIC4OxiNy3XLGmqbJOP6CxjoTPR2TLr+bj/C9Nsd5AwyzWITnTWMG2z1D0cEMGHR/XLubVgus2f78FNW9h+14vU90AwINh067l5zeZo9rNPTsTjV81IvP8vnJo8PbzuoQ0AP5s7MeO6HvnKyQC6LnJ8+upTEvddOmMUjh/Rx9YYiag4MYgmItfYndb7iizTouuMnluzKubq0pOPwsNfPsmVdbmV1M61FOL593cDSA46dzbF2xiePWGQvefOEiznGksf6bRff5zau9np2YmB9dX48Kh+acuZLjBdK6APNn57cbyW/Po545OW1QeR+uLPXpW8dp+oJ2MQTUQA3Any7Gair5szHk98LV4rbdVGTQeCxTAZi9043o1MfzpWsxh+bebRAJKD7o5IPAPcuyZebpDvjIzpzgTol5brSzzioP9y6hhy7WGdC/32+vMXP4xHrzw58XzXGhfL6qfu6nwSv+Erp45OGpsOouurGUQT9WQMookozmGM9/8+MwUNNd0nUMmVrsG1CsT9KucA8q+LTjfC2grvAqrUi+0AYNa4gdh067lJmdvUYDffMviAxbqArvZwuR7jOKm/T30PuFknr7fV6eMG4uQx/QHEX+dXTzs6abmuzifx3083uszokeguJn0ddGEhouLHIJqIXDFxWG9Hj9fBs3lWQx2U68DJ6TTMfmqotX+Akeqxr85AX9P6rCYa0Vl78yZL3XwqzyMEc/zqJLMecxBEp5azuHVgNap/LcYNqe92u/l16oA9MaW68dx6Cf3/gLoqbPzFHFfGRUTFi0E0EQHI/9R+KqcBrj5FbpmJNlJ+fmSiU2WLHQvRxWz66H5J28Jqu+ibknaLMThdW57vLIzm53FSneIkANfvszsumpL0u1PPfOtUy/aL5olxEuUcKe0DuzL7poC7CN6rROQtFmwREQDn7dycBrg6MDFfnBg2evcmMtEMTBKSWtdZBJL6tqT7jB+7pvnOry2c+T3i5O3ipF+yfg/oGQrtT7KSzGo2xk23npv0u87u6xkdUwN4D8veiagIMRNNRADsBwBuBbgVFpnodqMVms6cVrh4EZldxRInmYNjq6y0vj9pi5ky0R8e1deyfCGTqEtRoqNyjjQlFYWgn6nOuGCwq5wj/nqsymMK3VGGiAqHmWgicqQiKIjGlOMLvHRQZC4x0LFWouexzRZ6Tjgtc/GKOQNrDiT1RXud0fgBiFUmOhgQPH7VR/J+zmzBb64xtpNgPPWAKttU427S27K+KiWINl7O8SP64O7Pn5j0mLMnDsKW/UcKNkYiKhwG0UQEwH6wWBEMoD0cc9xqTAfPmbpztDuYpMNPXmRLrco5jm7shY37WqEUcOhIGIB1TbTd8bgxqyXgrCY6kJJpL9RBzuDe1Zg8PD6zoy796BpDXCgYwOxJyVO73/nZ5KCaiHoOBtFEBMB+OUdXuy+Xyjksss06QB87sA51FrWrXhpsurDMLi+6iliVczz21RloC0ext6UjMZW31UGJ7SDaeJMMaahOTNxih5NyDk2//ELVIS+5bhaUUvjiR0YlaqL1GDK9R4qhtzkReYNBNBE5ok+rO+1GkCmw06fw7/r81KQWeIUwdlA9Nt16LkZd84ztdXiTiTat3wjU+tfFLxQc3rdrwpqkjhoAPjFlKM6dnJwtzdWB1k4A1r2w83mJbiS0dfvDugJOaCIiuPH8+NTf9146NZFRP25wfbeLEImo52MQTUQA7F8wV+lSJlo73NG9ZENnU0MBKckOHW7OqqeZSysybfpYvMEJ7rtsGvrUVuDDo/rZfs4P9rUaz9f9CUMByTk47l/nbBKSRd8/DWMa63wNXM+eOBjPvrfTt+cnIv8xiCYiAPZPi+uL/YIuBYrNbeFutyUC9RIMoAFvyjnaTPXhmVavD0DOmjDI8XOGowqVoYDl8wUDAUSNloSZfPW0Mfj6zGMcjWNMY52jx7tl0rAGjGns5fcwiMgnDKKJyGAvitZtvdwIFP/4uRNxuD2CpZsOJN2uSzhKtb7Ui0x0q0XG3srtn5mCvS0drjxnRVAwZkAvHLI40AkGBIh0f0xNRTAp4G+sq3I0PXwxGdGvFou+P9PvYRCRT9gnmogcUQ47PpjNmTwEvWu6H9t7EYQW0hWnjHZ9ndefOx43nDcBQOazCI31VZgw1NmU7NqrPzwDj155MsKRroxzyNQn3NwpQwfKqfvucycd5cpYiIj85iiIFpF+IvK8iKw3/u+bZrnZIrJWRDaIyDWm228TkTUi8q6I/K+I9HEyHiKyz245h764ystSi1It4wDi2Vun5QtWPn/yUZ4E55kM6l2NPrWVCMdMQbQRJKfWRCemxjadPThuUD1qKoOFGSwRkcecZqKvAfCCUmosgBeM35OISBDAnQDOATABwCUiMsG4+3kAk5RSHwKwDsC1DsdDRDYdPdBenak+Ve9F14xaI+AKuTW3sw8KUYJS6OlgoqZ5u6tCxhTYKQc6uo7dfHOxTlxDRGSH02+muQAeNH5+EMAnLZaZDmCDUmqjUqoTwKPG46CUek4ppavolgAY7nA8RGTTD2ePw68+/aG8H6cn9fBCtdGP1+lsiH4q4SR6WuYZB3VmObVsY5fRR1ovOXviYHzyhGEFGR8RUSE4vbBwkFJqJwAopXaKyECLZYYB2Gr6fRuAkyyWuwLA/6R7IhG5EsCVADBy5EjbAyYia8GAoKE2/wu+4gGutxlGPYV1sUu9iA4o7LTUhWKq5uh2tqBfr0ocaO1MBNo63r770qkFHSMRkdeyBtEishDAYIu7rs/xOay+QZK+cUXkesSv63443UqUUvcCuBcApk2bxnOCRB7Qmd98nDJ2AG791GQPRtPV+WNonxp86sTiz2JaJcwLkUQvdLbbnInWM0jqCwxTp/RWhZpSkIiowLIG0UqpM9PdJyK7RWSIkYUeAmCPxWLbAIww/T4cwA7TOr4A4DwAsxT/2hL5qsZGEK2UwkAXpsbu0j0irAgE8Ov/ON7F5/CGVdlJIUpRvj3rWHzrjML9+TRP9NKr0giijXKOaMqMKxE3pickIipCTss5ngbwBQC3Gv8/ZbHMMgBjRWQ0gO0ALgbwWSDetQPADwGcppQ64nAsROSQnSC6EDFSZw6TeBQDqy4iXsfQS66dhcENbh7E5EeXc1QZ3TgqUy4wZRBNRD2V0wsLbwVwloisB3CW8TtEZKiIzAMA48LBqwEsALAawGNKqVXG4/8AoB7A8yLytojc7XA8RORAdUX+fxIKESKFSySItizn8Pg5/Qig66u68i+6K4v+P5ByIFFXxTm9iKhncvTXTSm1H8Asi9t3AJhj+n0egHkWy7nfPJWIbNPtyvLhZRWWXnNnpDSCaKtZG1ODyp5g9qTBeHzFNgBd2Xd9YWHqy73rcydiV3N7QcdHRFQIpdt8lYhcZ6cdc+qFZE6Z41C96lLJRPtVE11oN54/ES/950wAXQcJenKV1AOJk8b0x9zji/+iUCKifDGIJqIEOzMDxjyMb83dOYpB7+rMJ+9KeWbFfPSqCmHUgF4AAN0eerTx+/7WzsRyqfXRREQ9CYvViCjBqhwhG7cz0dqpYwegsa4KN18wOXHRmp9OP64RHxreB799YX3aZawy+T09rtaZ6Mb6KgBAh1F68/x3P4aB9f5d8EhE5DUG0USUYGeKaq9Kov/6Jas5mfzz58unY8Xmg5mDaIvtV4hpv/2kD7x0lw5t7KB6P4ZDRFQwDKKJKMFOOYIqSH+O4pAtHrYKou1k90uJ7g9da/SL/sjR/fH5k4/yc0hERAXBIJqIEuyVc3gwkCKV7SJBq2OQqUf19Wg0xUFvE90e8fKPjsZZEwb5OSQiooLwv9CQiIpGUXTncHVt7rIztt9dcoLr4ygm9dUVALoy0QygiahcMBNNRAm2unO4nIk+ZewA/GzuRHdX6hJb5Rw9+MrChd87DcP71uA/pg3H4IZqjGns5feQiIgKhploIkrIt6fxlOENOO3YRlfHUFsZwmUzRrm6TrdIhlz0P64+pbjT6B44ZmAdqiuCGNNYh9rKEBZ9f6bfQyIiKhhmookoId+s6VNXn+LRSIpTpmOMycMbeuTEKkREZI2ZaCJK6OmdJJzKtnnMd1cEuS2JiHoyBtFElBDowfW7bshUzgEkB9nhaBm1LSEiKkMMoomIcpQ9E82DECKicsEgmogoR1mDaOP+3158PE4dO8D7ARERkW8YRBMR2aDbuZkrYP5r9nG4fs54zD1+GC8yJCLq4didg4jIBh0i//VLJ6EqFM9HnDFuEM4YF7/9syeNxFH9a/0ZHBEReY5BNBFRjsyTM+pM8/ghvdGvV2W3ZT8+cTA+PnFwoYZGREQFxnIOIkqy9LpZfg+hJOhqDTY0ISIqTwyiiSjJwN7Vfg+hJOhOHOzIQURUnhhEExHZoDPRwr+iRERliX/+iYhyZFUTzS4cRETliUE0EZENrIkmIipvDKKJiGzQGWjWRBMRlSe2uCOivJ00uh9qK4N+D8NXOgPNag4iovLETDQR5W3soDr8+fLpfg+j4BS6iqKFNdFERGWNQTQRkQ3MRBMRlTcG0URENjATTURU3hhEE1HezK3eylWA3TmIiMoatc6ZyQAACBBJREFUg2giylusTINo88FDYsZCZqKJiMoSg2giylusTKPooX1qUBnin00iImIQTUQ2xMq0nqNfr0qsu+kcAMmdOoiIqPwwiCaivEXLNIgmIiLSGEQTUd4YQxMRUbljEE1EeYuWaU00ERGRxiCaiPLGcg4iIip3DKKJqJtQQDCgrirt/YpBNBERlTkG0UTUzYZfzMEnpgxJe38sVsDBEBERFaGQ3wMgouKUKdlcri3uzIb2qcG9l47xexhEROQTZqKJyFKmQJlBNBAQwdkTB/s9DCIi8omjIFpE+onI8yKy3vi/b5rlZovIWhHZICLXWNz/nyKiRGSAk/EQkXsyB9EFHAgREVERcpqJvgbAC0qpsQBeMH5PIiJBAHcCOAfABACXiMgE0/0jAJwFYIvDsRCRizIFymxxR0RE5c5pED0XwIPGzw8C+KTFMtMBbFBKbVRKdQJ41HicdgeA/wI4hy5RMdEdODbdem7ittkTB2PqUX1x5viBfg2raARE/B4CERH5yOmFhYOUUjsBQCm1U0SsvlmHAdhq+n0bgJMAQETOB7BdKfWOZPlCEpErAVwJACNHjnQ4bCLK5kunjMYxA+sTv4sAd1861ccRFY8nv/4RjO7fy+9hEBGRj7IG0SKyEIDV1TPX5/gcVtGxEpFaYx1n57ISpdS9AO4FgGnTpjFrTeSxYwbWJ4LoYEBYwmFy4kjLyz+IiKiMZA2ilVJnprtPRHaLyBAjCz0EwB6LxbYBGGH6fTiAHQCOBjAagM5CDwfwpohMV0rtyuM1EJHHKoIMoomIiMyclnM8DeALAG41/n/KYpllAMaKyGgA2wFcDOCzSqlVABLlHyKyCcA0pdQ+h2MiIpddNmMUDh3p9HsYRERERcNpEH0rgMdE5EuId9f4DACIyFAA9yul5iilIiJyNYAFAIIA/mQE0ERUIq6bM97vIRARERUVR0G0Umo/gFkWt+8AMMf0+zwA87Ksa5STsRARERERFQpnLCQiIiIiyhODaCIiIiKiPDGIJiIiIiLKE4NoIiIiIqI8MYgmIiIiIsoTg2giIiIiojwxiCYiIiIiypMoVXpT+YpIC4C1fo+DkgwAwNkmiw/3S/HhPilO3C/Fh/uk+JTrPjlKKdWYeqPTGQv9slYpNc3vQVAXEVnOfVJ8uF+KD/dJceJ+KT7cJ8WH+yQZyzmIiIiIiPLEIJqIiIiIKE+lGkTf6/cAqBvuk+LE/VJ8uE+KE/dL8eE+KT7cJyYleWEhEREREZGfSjUTTURERETkGwbRRERERER5KqkgWkRmi8haEdkgItf4PZ5ylG0fiMhMEWkSkbeNfzf4Mc5yJyJ/EpE9IrLS77GUo2zbn5+T4iAiI0TkRRFZLSKrROTbfo+p3OSyD/h58Z+IVIvIUhF5x9hPP/V7TMWgZGqiRSQIYB2AswBsA7AMwCVKqfd9HVgZyWUfiMhMAP+plDrPl0ESAEBEPgbgMICHlFKT/B5Pucm2/fk5KQ4iMgTAEKXUmyJSD2AFgE/ye6VwctkH/Lz4T0QEQC+l1GERqQDwKoBvK6WW+Dw0X5VSJno6gA1KqY1KqU4AjwKY6/OYyg33QYlQSi0GcMDvcZQrbv/SoJTaqZR60/i5BcBqAMP8HVV54T4oDSrusPFrhfGvNLKwHiqlIHoYgK2m37eBH7RCy3UfzDBO+TwrIhMLMzSiksPPSRERkVEATgDwhr8jKV9Z9gE/Lz4TkaCIvA1gD4DnlVJl/1kppWm/xeK2sj8KKrBc9sGbiM8xf1hE5gD4PwBjPR8ZUWnh56SIiEgdgCcAfEcp1ez3eMpRln3Az0sRUEpFARwvIn0A/K+ITFJKlfV1N6WUid4GYITp9+EAdvg0lnKVdR8opZr1KR+l1DwAFSIyoHBDJCp+/JwUD6O+8wkADyulnvR7POUo2z7g56W4KKUOAXgJwGyfh+K7UgqilwEYKyKjRaQSwMUAnvZ5TOUm6z4QkcHGBQgQkemIv8f2F3ykREWMn5PiYOyDBwCsVkr92u/xlKNc9gE/L/4TkUYjAw0RqQFwJoA1/o7KfyVTzqGUiojI1QAWAAgC+JNSapXPwyor6faBiFxl3H83gAsBfE1EIgDaAFysSqUFTA8iIo8AmAlggIhsA/ATpdQD/o6qfFhtf8QvxOHnpLh8FMClAN4zaj0B4Doj20mFYbkPAIwE+HkpIkMAPGh06QoAeEwp9U+fx+S7kmlxR0RERERULEqpnIOIiIiIqCgwiCYiIiIiyhODaCIiIiKiPDGIJiIiIiLKE4NoIiIiIqI8MYgmIipBItJfRN42/u0Ske3Gz4dF5I9+j4+IqKdjizsiohInIjcCOKyUut3vsRARlQtmoomIehARmSki/zR+vlFEHhSR50Rkk4h8SkR+JSLvich8Y7pliMhUEXlZRFaIyAIRGeLvqyAiKn4MoomIerajAZwLYC6AvwF4USk1GfGZ3841AunfA7hQKTUVwJ8A3OzXYImISkXJTPtNRES2PKuUCovIewCCAOYbt78HYBSA4wBMAvC8iMBYZqcP4yQiKikMoomIerYOAFBKxUQkrLouhIkh/h0gAFYppWb4NUAiolLEcg4iovK2FkCjiMwAABGpEJGJPo+JiKjoMYgmIipjSqlOABcC+KWIvAPgbQAf8XdURETFjy3uiIiIiIjyxEw0EREREVGeGEQTEREREeWJQTQRERERUZ4YRBMRERER5YlBNBERERFRnhhEExERERHliUE0EREREVGe/j+C812RgTrDHgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import glob\n",
        "\n",
        "data, sampling_rate = librosa.load('D://ITC//final_project//data//data//Actor_01//03-01-01-01-01-01-01.wav')\n",
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.waveplot(data, sr=sampling_rate)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UfekbSE_lWn"
      },
      "source": [
        "### Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "4cee5215f2d3496586b8989d2c98e83f"
          ]
        },
        "id": "UePpaKr6_lWn",
        "outputId": "a7b0a38e-661d-4c19-f9e6-1e02f737fc95"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cee5215f2d3496586b8989d2c98e83f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Talba\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        }
      ],
      "source": [
        "lst = []\n",
        "path = 'D://ITC//final_project//data'\n",
        "\n",
        "for root, dirs, files in tqdm(os.walk(path)):\n",
        "    for file in files:\n",
        "        try:\n",
        "            #Load librosa array, obtain mfcss, store the file and the mfcss information in a new array\n",
        "            X, sample_rate = librosa.load(os.path.join(root,file), res_type='kaiser_fast')\n",
        "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
        "            # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "            file = int(file[7:8])\n",
        "            arr = mfccs, file\n",
        "            lst.append(arr)\n",
        "          # If the file is not valid, skip it\n",
        "        except ValueError:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ukbkTGR_lWn"
      },
      "outputs": [],
      "source": [
        "X, y = zip(*lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUTm7Txa_lWn",
        "outputId": "ec40ea82-2898-480d-86e6-b7b2bfd6d95b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2628, 40), (2628,))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eag0xOPO_lWo"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "\n",
        "# with open('d://ITC//final_project//x.pickle', 'wb') as f:\n",
        "#     pickle.dump(X, f)\n",
        "# with open('d://ITC//final_project//y.pickle', 'wb') as f:\n",
        "#     pickle.dump(y, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15kDpKIl_lWo"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "\n",
        "# with open('d://ITC//final_project//x.pickle', 'rb') as f:\n",
        "#     X = pickle.load(f)\n",
        "# with open('d://ITC//final_project//y.pickle', 'rb') as f:\n",
        "#     y = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX4AkMhe_lWo",
        "outputId": "649b3452-81e5-4f81-973f-5a34298db3c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1, 2, 3, 4, 5, 6, 7, 8}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvE0JBdv_lWo"
      },
      "outputs": [],
      "source": [
        "emotions = {1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'happy', 6:'fearful', 7:'disgust', 8:'surprised'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hAZ0yas_lWo",
        "outputId": "70b3fb57-b816-4306-8ccd-edeff16d4e6e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.title('Distribution of target variable:')\n",
        "sns.countplot(y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwWqxW-s_lWp"
      },
      "source": [
        "### Spotting outliers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_SRJ2mne_lWp"
      },
      "outputs": [],
      "source": [
        "for i in X_df:\n",
        "    Q1 = X_df[i].quantile(0.25)\n",
        "    Q3 = X_df[i].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    print(f'Outliers in {i}:')\n",
        "    print(np.array((X_df[i] < (Q1 - 1.5 * IQR)) |(X_df[i] > (Q3 + 1.5 * IQR))).nonzero())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eJVEn4Zx_lWp"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,40))\n",
        "for i,col in enumerate(X_df):\n",
        "    plt.title(i, fontsize=20)\n",
        "    plt.subplot(8,5,i+1)\n",
        "    X_df[[col]].boxplot(fontsize=20)\n",
        "plt.subplots_adjust(hspace=0.5, wspace=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu7tedOe_lWq"
      },
      "source": [
        "### outliers in these features-\n",
        "\n",
        "- 0- <-1000\n",
        "- 6- <-10\n",
        "- 10- >20\n",
        "- 12 >20\n",
        "- 25 >10\n",
        "- 26 >15\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXHiwD5d_lWq"
      },
      "source": [
        "### replacing the outliers with median:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy2_ni-L_lWq"
      },
      "outputs": [],
      "source": [
        "median = X_df.loc[X_df[0] > -1000, 0].median()\n",
        "X_df.loc[X_df[0] < -1000, 0] = np.nan\n",
        "X_df[0].fillna(median,inplace=True)\n",
        "\n",
        "median = X_df.loc[X_df[6] > -1000, 6].median()\n",
        "X_df.loc[X_df[6] < -1000, 6] = np.nan\n",
        "X_df[6].fillna(median,inplace=True)\n",
        "\n",
        "median = X_df.loc[X_df[10] > -1000, 10].median()\n",
        "X_df.loc[X_df[10] < -1000, 10] = np.nan\n",
        "X_df[10].fillna(median,inplace=True)\n",
        "\n",
        "median = X_df.loc[X_df[12] > -1000, 12].median()\n",
        "X_df.loc[X_df[12] < -1000,12] = np.nan\n",
        "X_df[12].fillna(median,inplace=True)\n",
        "\n",
        "median = X_df.loc[X_df[25] > -1000, 25].median()\n",
        "X_df.loc[X_df[25] < -1000, 25] = np.nan\n",
        "X_df[25].fillna(median,inplace=True)\n",
        "\n",
        "median = X_df.loc[X_df[26] > -1000, 26].median()\n",
        "X_df.loc[X_df[26] < -1000, 26] = np.nan\n",
        "X_df[26].fillna(median,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRdDrCsG_lWq"
      },
      "source": [
        "### At this point, we can perform a normal classification, using our mfccs coefficients as our features.\n",
        "\n",
        "### We'll start by running a Logistic regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuT1SS9f_lWr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, \\\n",
        "                                                    random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2K8BOif_lWr",
        "outputId": "b2a0c5b6-be27-4c99-be67-8862a11bc068"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Talba\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression(max_iter=150).fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rnxWarb_lWr",
        "outputId": "301a217b-fd54-4a3b-8cf2-417ff56b423b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.73      0.40      0.52        40\n",
            "           2       0.46      0.51      0.48        81\n",
            "           3       0.54      0.56      0.55        85\n",
            "           4       0.46      0.56      0.50        73\n",
            "           5       0.60      0.70      0.65        79\n",
            "           6       0.64      0.62      0.63        90\n",
            "           7       0.47      0.38      0.42        39\n",
            "           8       0.40      0.26      0.31        39\n",
            "\n",
            "    accuracy                           0.54       526\n",
            "   macro avg       0.54      0.50      0.51       526\n",
            "weighted avg       0.54      0.54      0.53       526\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piRk0_2Z_lWs"
      },
      "source": [
        "### Running RandomForest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7femqXT_lWs"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "reg = RandomForestClassifier()\n",
        "reg.fit(X_train, y_train)\n",
        "y_pred2 = reg.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-y93ep6_lWs",
        "outputId": "95d88d76-2bdd-442b-ff0b-8a4cc8a3f2be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.90      0.65      0.75        40\n",
            "           2       0.64      0.89      0.75        81\n",
            "           3       0.78      0.61      0.68        85\n",
            "           4       0.66      0.73      0.69        73\n",
            "           5       0.79      0.75      0.77        79\n",
            "           6       0.80      0.76      0.78        90\n",
            "           7       0.74      0.59      0.66        39\n",
            "           8       0.45      0.54      0.49        39\n",
            "\n",
            "    accuracy                           0.71       526\n",
            "   macro avg       0.72      0.69      0.70       526\n",
            "weighted avg       0.73      0.71      0.71       526\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0k6ZYeDJ_lWs"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "y_pred3 = gnb.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ODfuNBP_lWt",
        "outputId": "41609c11-281e-4d44-a0a5-b1e0d522a98a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.45      0.38      0.41        40\n",
            "           2       0.60      0.40      0.48        81\n",
            "           3       0.61      0.40      0.48        85\n",
            "           4       0.45      0.29      0.35        73\n",
            "           5       0.68      0.49      0.57        79\n",
            "           6       0.60      0.34      0.44        90\n",
            "           7       0.20      0.62      0.30        39\n",
            "           8       0.24      0.64      0.34        39\n",
            "\n",
            "    accuracy                           0.42       526\n",
            "   macro avg       0.48      0.44      0.42       526\n",
            "weighted avg       0.52      0.42      0.44       526\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orKXpT0P_lWt"
      },
      "source": [
        "### trying KNN, and therefore scale the features before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4Dsv-9A_lWt"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scale = scaler.transform(X_train)\n",
        "X_test_scale = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIzCrKWq_lWt"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train_scale, y_train)\n",
        "y_pred4 = knn.predict(X_test_scale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouMZvfH4_lWt",
        "outputId": "e20b4401-4bc1-4be4-8e6e-fa47786c681b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.52      0.82      0.64        40\n",
            "           2       0.84      0.83      0.83        81\n",
            "           3       0.67      0.74      0.70        85\n",
            "           4       0.75      0.67      0.71        73\n",
            "           5       0.71      0.82      0.76        79\n",
            "           6       0.85      0.62      0.72        90\n",
            "           7       0.91      0.54      0.68        39\n",
            "           8       0.67      0.74      0.71        39\n",
            "\n",
            "    accuracy                           0.73       526\n",
            "   macro avg       0.74      0.72      0.72       526\n",
            "weighted avg       0.75      0.73      0.73       526\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL9lP_00_lWv"
      },
      "source": [
        "### Running basic neural network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frcr416f_lWv",
        "outputId": "168de824-4b64-47a3-f9db-7b7658213c09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2102, 40)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KGkDR64_lWv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "model = Sequential(\n",
        "    [\n",
        "     layers.Dense(256, activation=\"sigmoid\", input_dim = 40),\n",
        "     layers.Dense(64, activation=\"relu\"),\n",
        "     layers.Dense(8, activation=\"softmax\")\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHru_v5X_lWv",
        "outputId": "b832485f-bde6-46d3-c08e-f9af3d99845a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((None, 40), (None, 8))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.input_shape, model.output_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUU2zpdj_lWw",
        "outputId": "d288a2b2-8d81-4642-ddb0-6c789f6e91ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 256)               10496     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 520       \n",
            "=================================================================\n",
            "Total params: 27,464\n",
            "Trainable params: 27,464\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc3Hmtp9_lWw"
      },
      "outputs": [],
      "source": [
        "y_train = y_train - 1\n",
        "y_test = y_test - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KACNKX-U_lWw",
        "outputId": "8a588124-fb54-4ee4-b45a-3993b7755f2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0i8mpj_m_lWw",
        "outputId": "3b88890e-ff62-4012-8537-923b2179ac02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 0.1197 - accuracy: 0.9522 - val_loss: 1.9800 - val_accuracy: 0.6351\n",
            "Epoch 2/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 0.9417 - val_loss: 2.3756 - val_accuracy: 0.6445\n",
            "Epoch 3/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9327 - val_loss: 2.0302 - val_accuracy: 0.6635\n",
            "Epoch 4/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1593 - accuracy: 0.9455 - val_loss: 1.9600 - val_accuracy: 0.6919\n",
            "Epoch 5/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9492 - val_loss: 2.1258 - val_accuracy: 0.6209\n",
            "Epoch 6/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.9475 - val_loss: 2.1504 - val_accuracy: 0.6351\n",
            "Epoch 7/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9375 - val_loss: 1.8861 - val_accuracy: 0.6540\n",
            "Epoch 8/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1491 - accuracy: 0.9503 - val_loss: 2.1908 - val_accuracy: 0.6161\n",
            "Epoch 9/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.8999 - val_loss: 2.2688 - val_accuracy: 0.6209\n",
            "Epoch 10/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8982 - val_loss: 1.7913 - val_accuracy: 0.6682\n",
            "Epoch 11/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1711 - accuracy: 0.9398 - val_loss: 1.7664 - val_accuracy: 0.6682\n",
            "Epoch 12/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0905 - accuracy: 0.9645 - val_loss: 1.8468 - val_accuracy: 0.6682\n",
            "Epoch 13/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0864 - accuracy: 0.9659 - val_loss: 1.8263 - val_accuracy: 0.6682\n",
            "Epoch 14/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0810 - accuracy: 0.9694 - val_loss: 1.8359 - val_accuracy: 0.6730\n",
            "Epoch 15/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.9752 - val_loss: 1.9748 - val_accuracy: 0.6825\n",
            "Epoch 16/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.9676 - val_loss: 1.9747 - val_accuracy: 0.6682\n",
            "Epoch 17/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.9649 - val_loss: 2.0607 - val_accuracy: 0.6635\n",
            "Epoch 18/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9597 - val_loss: 2.2538 - val_accuracy: 0.6114\n",
            "Epoch 19/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.9079 - val_loss: 2.4802 - val_accuracy: 0.6066\n",
            "Epoch 20/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.8379 - val_loss: 1.8551 - val_accuracy: 0.6066\n",
            "Epoch 21/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9201 - val_loss: 2.0530 - val_accuracy: 0.6161\n",
            "Epoch 22/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9287 - val_loss: 2.0086 - val_accuracy: 0.6825\n",
            "Epoch 23/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1095 - accuracy: 0.9623 - val_loss: 1.8014 - val_accuracy: 0.6682\n",
            "Epoch 24/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.9672 - val_loss: 2.0221 - val_accuracy: 0.6682\n",
            "Epoch 25/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1132 - accuracy: 0.9617 - val_loss: 1.9897 - val_accuracy: 0.6730\n",
            "Epoch 26/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0894 - accuracy: 0.9666 - val_loss: 1.8507 - val_accuracy: 0.6825\n",
            "Epoch 27/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.9700 - val_loss: 1.9935 - val_accuracy: 0.6777\n",
            "Epoch 28/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1033 - accuracy: 0.9637 - val_loss: 2.1046 - val_accuracy: 0.6682\n",
            "Epoch 29/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1246 - accuracy: 0.9499 - val_loss: 1.9830 - val_accuracy: 0.6540\n",
            "Epoch 30/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9583 - val_loss: 2.0872 - val_accuracy: 0.6540\n",
            "Epoch 31/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1351 - accuracy: 0.9518 - val_loss: 1.8926 - val_accuracy: 0.6540\n",
            "Epoch 32/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8847 - val_loss: 2.2319 - val_accuracy: 0.6019\n",
            "Epoch 33/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.8175 - val_loss: 2.0448 - val_accuracy: 0.6256\n",
            "Epoch 34/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1509 - accuracy: 0.9340 - val_loss: 2.0897 - val_accuracy: 0.6256\n",
            "Epoch 35/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9567 - val_loss: 1.9932 - val_accuracy: 0.6256\n",
            "Epoch 36/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.9653 - val_loss: 2.1245 - val_accuracy: 0.6209\n",
            "Epoch 37/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.9554 - val_loss: 2.0053 - val_accuracy: 0.6303\n",
            "Epoch 38/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0862 - accuracy: 0.9668 - val_loss: 2.0833 - val_accuracy: 0.6398\n",
            "Epoch 39/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.9707 - val_loss: 2.1594 - val_accuracy: 0.6398\n",
            "Epoch 40/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.9630 - val_loss: 2.0393 - val_accuracy: 0.6493\n",
            "Epoch 41/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0885 - accuracy: 0.9719 - val_loss: 2.2002 - val_accuracy: 0.5924\n",
            "Epoch 42/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.8934 - val_loss: 2.1362 - val_accuracy: 0.6161\n",
            "Epoch 43/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 0.8833 - val_loss: 2.0276 - val_accuracy: 0.6161\n",
            "Epoch 44/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1646 - accuracy: 0.9449 - val_loss: 1.9661 - val_accuracy: 0.6445\n",
            "Epoch 45/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1337 - accuracy: 0.9547 - val_loss: 1.9857 - val_accuracy: 0.6398\n",
            "Epoch 46/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9630 - val_loss: 2.1011 - val_accuracy: 0.6682\n",
            "Epoch 47/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.9496 - val_loss: 1.9623 - val_accuracy: 0.6872\n",
            "Epoch 48/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9486 - val_loss: 1.9554 - val_accuracy: 0.6635\n",
            "Epoch 49/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.9647 - val_loss: 2.0032 - val_accuracy: 0.6588\n",
            "Epoch 50/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.9678 - val_loss: 2.0197 - val_accuracy: 0.6682\n",
            "Epoch 51/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.9721 - val_loss: 2.0086 - val_accuracy: 0.6635\n",
            "Epoch 52/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0797 - accuracy: 0.9671 - val_loss: 2.0497 - val_accuracy: 0.6588\n",
            "Epoch 53/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9717 - val_loss: 2.1667 - val_accuracy: 0.6398\n",
            "Epoch 54/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.9612 - val_loss: 2.1579 - val_accuracy: 0.6303\n",
            "Epoch 55/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.8464 - val_loss: 1.5482 - val_accuracy: 0.5972\n",
            "Epoch 56/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4310 - accuracy: 0.8516 - val_loss: 2.0228 - val_accuracy: 0.6114\n",
            "Epoch 57/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1655 - accuracy: 0.9454 - val_loss: 1.9026 - val_accuracy: 0.6351\n",
            "Epoch 58/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1531 - accuracy: 0.9433 - val_loss: 1.9176 - val_accuracy: 0.6635\n",
            "Epoch 59/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.9564 - val_loss: 1.8905 - val_accuracy: 0.6682\n",
            "Epoch 60/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.9629 - val_loss: 1.9330 - val_accuracy: 0.6256\n",
            "Epoch 61/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.9621 - val_loss: 1.9344 - val_accuracy: 0.6635\n",
            "Epoch 62/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0857 - accuracy: 0.9666 - val_loss: 2.0339 - val_accuracy: 0.6398\n",
            "Epoch 63/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9519 - val_loss: 2.5092 - val_accuracy: 0.5829\n",
            "Epoch 64/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.8453 - val_loss: 1.8457 - val_accuracy: 0.6682\n",
            "Epoch 65/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8837 - val_loss: 1.8113 - val_accuracy: 0.6682\n",
            "Epoch 66/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9305 - val_loss: 1.8687 - val_accuracy: 0.6445\n",
            "Epoch 67/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9546 - val_loss: 1.9361 - val_accuracy: 0.6682\n",
            "Epoch 68/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9437 - val_loss: 1.8578 - val_accuracy: 0.6682\n",
            "Epoch 69/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0840 - accuracy: 0.9719 - val_loss: 1.8731 - val_accuracy: 0.6635\n",
            "Epoch 70/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0955 - accuracy: 0.9653 - val_loss: 1.9659 - val_accuracy: 0.6825\n",
            "Epoch 71/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9626 - val_loss: 1.9578 - val_accuracy: 0.6825\n",
            "Epoch 72/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9633 - val_loss: 1.9571 - val_accuracy: 0.6682\n",
            "Epoch 73/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.9705 - val_loss: 2.1051 - val_accuracy: 0.6303\n",
            "Epoch 74/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.9047 - val_loss: 1.9009 - val_accuracy: 0.6398\n",
            "Epoch 75/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8730 - val_loss: 1.8611 - val_accuracy: 0.6540\n",
            "Epoch 76/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.9478 - val_loss: 1.9199 - val_accuracy: 0.6730\n",
            "Epoch 77/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.9672 - val_loss: 2.0037 - val_accuracy: 0.6493\n",
            "Epoch 78/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1031 - accuracy: 0.9611 - val_loss: 2.0322 - val_accuracy: 0.6445\n",
            "Epoch 79/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9627 - val_loss: 2.1718 - val_accuracy: 0.6493\n",
            "Epoch 80/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.9754 - val_loss: 2.0262 - val_accuracy: 0.6540\n",
            "Epoch 81/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.9649 - val_loss: 2.0417 - val_accuracy: 0.6540\n",
            "Epoch 82/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0908 - accuracy: 0.9648 - val_loss: 2.0633 - val_accuracy: 0.6635\n",
            "Epoch 83/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.9282 - val_loss: 2.2883 - val_accuracy: 0.6066\n",
            "Epoch 84/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8623 - val_loss: 1.6632 - val_accuracy: 0.6445\n",
            "Epoch 85/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.9172 - val_loss: 1.8358 - val_accuracy: 0.6682\n",
            "Epoch 86/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9512 - val_loss: 1.9622 - val_accuracy: 0.6730\n",
            "Epoch 87/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9436 - val_loss: 1.9179 - val_accuracy: 0.6635\n",
            "Epoch 88/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9423 - val_loss: 2.2165 - val_accuracy: 0.6161\n",
            "Epoch 89/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1401 - accuracy: 0.9417 - val_loss: 2.0175 - val_accuracy: 0.6540\n",
            "Epoch 90/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1081 - accuracy: 0.9617 - val_loss: 2.2809 - val_accuracy: 0.6398\n",
            "Epoch 91/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9343 - val_loss: 2.0364 - val_accuracy: 0.6303\n",
            "Epoch 92/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9407 - val_loss: 2.0956 - val_accuracy: 0.6303\n",
            "Epoch 93/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9511 - val_loss: 2.0640 - val_accuracy: 0.6303\n",
            "Epoch 94/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.9657 - val_loss: 1.9857 - val_accuracy: 0.6682\n",
            "Epoch 95/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 0.9698 - val_loss: 1.9993 - val_accuracy: 0.6682\n",
            "Epoch 96/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.9696 - val_loss: 1.9390 - val_accuracy: 0.6540\n",
            "Epoch 97/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.9614 - val_loss: 2.0956 - val_accuracy: 0.6540\n",
            "Epoch 98/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0914 - accuracy: 0.9649 - val_loss: 2.0271 - val_accuracy: 0.6682\n",
            "Epoch 99/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9750 - val_loss: 1.8987 - val_accuracy: 0.6635\n",
            "Epoch 100/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.9554 - val_loss: 1.9957 - val_accuracy: 0.6493\n",
            "Epoch 101/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.9036 - val_loss: 2.0899 - val_accuracy: 0.6351\n",
            "Epoch 102/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9232 - val_loss: 2.0093 - val_accuracy: 0.6398\n",
            "Epoch 103/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.8975 - val_loss: 1.8973 - val_accuracy: 0.6635\n",
            "Epoch 104/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.2127 - accuracy: 0.9246 - val_loss: 1.9850 - val_accuracy: 0.6635\n",
            "Epoch 105/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.9589 - val_loss: 2.1239 - val_accuracy: 0.6682\n",
            "Epoch 106/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1046 - accuracy: 0.9593 - val_loss: 2.0772 - val_accuracy: 0.6777\n",
            "Epoch 107/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.9669 - val_loss: 2.0952 - val_accuracy: 0.6967\n",
            "Epoch 108/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9694 - val_loss: 2.0256 - val_accuracy: 0.6777\n",
            "Epoch 109/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9739 - val_loss: 2.0165 - val_accuracy: 0.6540\n",
            "Epoch 110/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.9702 - val_loss: 2.0557 - val_accuracy: 0.6588\n",
            "Epoch 111/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.9716 - val_loss: 2.0526 - val_accuracy: 0.6825\n",
            "Epoch 112/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.9764 - val_loss: 2.0669 - val_accuracy: 0.6919\n",
            "Epoch 113/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9616 - val_loss: 2.2032 - val_accuracy: 0.6588\n",
            "Epoch 114/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9194 - val_loss: 2.1223 - val_accuracy: 0.6209\n",
            "Epoch 115/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8747 - val_loss: 2.3334 - val_accuracy: 0.6066\n",
            "Epoch 116/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.9071 - val_loss: 1.8424 - val_accuracy: 0.6351\n",
            "Epoch 117/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9471 - val_loss: 2.0311 - val_accuracy: 0.6256\n",
            "Epoch 118/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.9622 - val_loss: 2.0904 - val_accuracy: 0.6445\n",
            "Epoch 119/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9565 - val_loss: 2.1534 - val_accuracy: 0.6209\n",
            "Epoch 120/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.9625 - val_loss: 2.0281 - val_accuracy: 0.6303\n",
            "Epoch 121/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9748 - val_loss: 2.0585 - val_accuracy: 0.6351\n",
            "Epoch 122/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9728 - val_loss: 2.0403 - val_accuracy: 0.6209\n",
            "Epoch 123/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9719 - val_loss: 1.9922 - val_accuracy: 0.6351\n",
            "Epoch 124/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9740 - val_loss: 2.1507 - val_accuracy: 0.6209\n",
            "Epoch 125/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9664 - val_loss: 2.0157 - val_accuracy: 0.6256\n",
            "Epoch 126/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9669 - val_loss: 2.1147 - val_accuracy: 0.6493\n",
            "Epoch 127/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9430 - val_loss: 2.1895 - val_accuracy: 0.6019\n",
            "Epoch 128/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8800 - val_loss: 1.8737 - val_accuracy: 0.6398\n",
            "Epoch 129/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.9234 - val_loss: 2.1562 - val_accuracy: 0.6066\n",
            "Epoch 130/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9261 - val_loss: 2.1023 - val_accuracy: 0.6114\n",
            "Epoch 131/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.2159 - accuracy: 0.9209 - val_loss: 2.0941 - val_accuracy: 0.6209\n",
            "Epoch 132/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1395 - accuracy: 0.9610 - val_loss: 2.0141 - val_accuracy: 0.6682\n",
            "Epoch 133/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9655 - val_loss: 2.2247 - val_accuracy: 0.5924\n",
            "Epoch 134/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.9688 - val_loss: 2.0885 - val_accuracy: 0.6635\n",
            "Epoch 135/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9702 - val_loss: 2.0527 - val_accuracy: 0.6445\n",
            "Epoch 136/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9739 - val_loss: 2.2008 - val_accuracy: 0.6540\n",
            "Epoch 137/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0918 - accuracy: 0.9658 - val_loss: 2.2174 - val_accuracy: 0.6351\n",
            "Epoch 138/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.9745 - val_loss: 2.0912 - val_accuracy: 0.6303\n",
            "Epoch 139/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.9611 - val_loss: 2.0887 - val_accuracy: 0.6303\n",
            "Epoch 140/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9697 - val_loss: 2.1487 - val_accuracy: 0.6635\n",
            "Epoch 141/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9702 - val_loss: 2.1254 - val_accuracy: 0.6493\n",
            "Epoch 142/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0849 - accuracy: 0.9644 - val_loss: 2.1732 - val_accuracy: 0.6351\n",
            "Epoch 143/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.6056 - accuracy: 0.8117 - val_loss: 1.6198 - val_accuracy: 0.6256\n",
            "Epoch 144/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9214 - val_loss: 2.2878 - val_accuracy: 0.6019\n",
            "Epoch 145/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1734 - accuracy: 0.9474 - val_loss: 2.0713 - val_accuracy: 0.6493\n",
            "Epoch 146/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9531 - val_loss: 2.2051 - val_accuracy: 0.6351\n",
            "Epoch 147/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.9372 - val_loss: 2.0131 - val_accuracy: 0.6303\n",
            "Epoch 148/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9703 - val_loss: 2.1138 - val_accuracy: 0.6445\n",
            "Epoch 149/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0807 - accuracy: 0.9681 - val_loss: 2.2039 - val_accuracy: 0.6303\n",
            "Epoch 150/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9700 - val_loss: 2.2149 - val_accuracy: 0.6351\n",
            "Epoch 151/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0810 - accuracy: 0.9701 - val_loss: 2.1678 - val_accuracy: 0.6303\n",
            "Epoch 152/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9730 - val_loss: 2.1785 - val_accuracy: 0.6445\n",
            "Epoch 153/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.9683 - val_loss: 2.2070 - val_accuracy: 0.6493\n",
            "Epoch 154/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9713 - val_loss: 2.1081 - val_accuracy: 0.6635\n",
            "Epoch 155/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0991 - accuracy: 0.9587 - val_loss: 2.2022 - val_accuracy: 0.6540\n",
            "Epoch 156/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.9712 - val_loss: 2.2443 - val_accuracy: 0.6635\n",
            "Epoch 157/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.9709 - val_loss: 2.2807 - val_accuracy: 0.6445\n",
            "Epoch 158/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.9466 - val_loss: 2.4196 - val_accuracy: 0.6209\n",
            "Epoch 159/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.8018 - val_loss: 1.8874 - val_accuracy: 0.5687\n",
            "Epoch 160/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8759 - val_loss: 1.8596 - val_accuracy: 0.6445\n",
            "Epoch 161/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9165 - val_loss: 1.9744 - val_accuracy: 0.6398\n",
            "Epoch 162/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9336 - val_loss: 1.8866 - val_accuracy: 0.6066\n",
            "Epoch 163/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9305 - val_loss: 2.0768 - val_accuracy: 0.6209\n",
            "Epoch 164/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9411 - val_loss: 2.0247 - val_accuracy: 0.6398\n",
            "Epoch 165/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1223 - accuracy: 0.9561 - val_loss: 1.9954 - val_accuracy: 0.6398\n",
            "Epoch 166/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0908 - accuracy: 0.9693 - val_loss: 2.0346 - val_accuracy: 0.6730\n",
            "Epoch 167/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9511 - val_loss: 2.0559 - val_accuracy: 0.6730\n",
            "Epoch 168/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.9586 - val_loss: 1.9407 - val_accuracy: 0.6588\n",
            "Epoch 169/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9606 - val_loss: 1.9321 - val_accuracy: 0.6588\n",
            "Epoch 170/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2556 - accuracy: 0.9088 - val_loss: 2.0899 - val_accuracy: 0.6161\n",
            "Epoch 171/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1725 - accuracy: 0.9357 - val_loss: 2.0174 - val_accuracy: 0.6540\n",
            "Epoch 172/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 0.9563 - val_loss: 2.0442 - val_accuracy: 0.6351\n",
            "Epoch 173/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9466 - val_loss: 1.9956 - val_accuracy: 0.6730\n",
            "Epoch 174/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 0.9688 - val_loss: 2.0339 - val_accuracy: 0.6303\n",
            "Epoch 175/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9720 - val_loss: 2.0514 - val_accuracy: 0.6635\n",
            "Epoch 176/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.9661 - val_loss: 2.1622 - val_accuracy: 0.6493\n",
            "Epoch 177/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.9682 - val_loss: 2.0520 - val_accuracy: 0.6445\n",
            "Epoch 178/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9334 - val_loss: 2.1964 - val_accuracy: 0.6303\n",
            "Epoch 179/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.9156 - val_loss: 2.2270 - val_accuracy: 0.6066\n",
            "Epoch 180/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9449 - val_loss: 1.8698 - val_accuracy: 0.6540\n",
            "Epoch 181/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9739 - val_loss: 1.9882 - val_accuracy: 0.6540\n",
            "Epoch 182/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.9695 - val_loss: 2.0591 - val_accuracy: 0.6635\n",
            "Epoch 183/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9718 - val_loss: 2.1335 - val_accuracy: 0.6588\n",
            "Epoch 184/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9744 - val_loss: 2.0752 - val_accuracy: 0.6635\n",
            "Epoch 185/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9719 - val_loss: 2.0945 - val_accuracy: 0.6540\n",
            "Epoch 186/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9632 - val_loss: 2.0798 - val_accuracy: 0.6635\n",
            "Epoch 187/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9730 - val_loss: 2.1278 - val_accuracy: 0.6588\n",
            "Epoch 188/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.9648 - val_loss: 2.1317 - val_accuracy: 0.6493\n",
            "Epoch 189/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9710 - val_loss: 2.1207 - val_accuracy: 0.6493\n",
            "Epoch 190/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.9547 - val_loss: 2.6341 - val_accuracy: 0.5735\n",
            "Epoch 191/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.8370 - accuracy: 0.7785 - val_loss: 1.9416 - val_accuracy: 0.5877\n",
            "Epoch 192/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.8963 - val_loss: 1.9877 - val_accuracy: 0.6114\n",
            "Epoch 193/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9304 - val_loss: 2.0415 - val_accuracy: 0.6303\n",
            "Epoch 194/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9289 - val_loss: 1.9811 - val_accuracy: 0.6493\n",
            "Epoch 195/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0953 - accuracy: 0.9635 - val_loss: 2.0609 - val_accuracy: 0.6540\n",
            "Epoch 196/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9734 - val_loss: 2.0172 - val_accuracy: 0.6493\n",
            "Epoch 197/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9715 - val_loss: 2.0512 - val_accuracy: 0.6730\n",
            "Epoch 198/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 0.9713 - val_loss: 2.0092 - val_accuracy: 0.6635\n",
            "Epoch 199/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.9727 - val_loss: 2.1076 - val_accuracy: 0.6493\n",
            "Epoch 200/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.9691 - val_loss: 2.1782 - val_accuracy: 0.6445\n",
            "Epoch 201/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9527 - val_loss: 2.2308 - val_accuracy: 0.6540\n",
            "Epoch 202/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4000 - accuracy: 0.8534 - val_loss: 2.0776 - val_accuracy: 0.6588\n",
            "Epoch 203/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9295 - val_loss: 1.7645 - val_accuracy: 0.6588\n",
            "Epoch 204/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9511 - val_loss: 1.9723 - val_accuracy: 0.6445\n",
            "Epoch 205/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.9545 - val_loss: 2.0491 - val_accuracy: 0.6303\n",
            "Epoch 206/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.9716 - val_loss: 2.0162 - val_accuracy: 0.6398\n",
            "Epoch 207/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.9630 - val_loss: 2.0116 - val_accuracy: 0.6398\n",
            "Epoch 208/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9736 - val_loss: 2.0242 - val_accuracy: 0.6588\n",
            "Epoch 209/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9676 - val_loss: 2.1121 - val_accuracy: 0.6445\n",
            "Epoch 210/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 0.9709 - val_loss: 2.1270 - val_accuracy: 0.6445\n",
            "Epoch 211/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9727 - val_loss: 1.9811 - val_accuracy: 0.6635\n",
            "Epoch 212/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.9649 - val_loss: 2.2405 - val_accuracy: 0.6493\n",
            "Epoch 213/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1801 - accuracy: 0.9362 - val_loss: 2.2210 - val_accuracy: 0.6256\n",
            "Epoch 214/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8753 - val_loss: 2.2551 - val_accuracy: 0.6445\n",
            "Epoch 215/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8660 - val_loss: 1.9896 - val_accuracy: 0.6066\n",
            "Epoch 216/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.9343 - val_loss: 1.9028 - val_accuracy: 0.6398\n",
            "Epoch 217/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9423 - val_loss: 2.0613 - val_accuracy: 0.6398\n",
            "Epoch 218/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0928 - accuracy: 0.9622 - val_loss: 1.9672 - val_accuracy: 0.6588\n",
            "Epoch 219/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9718 - val_loss: 1.9960 - val_accuracy: 0.6493\n",
            "Epoch 220/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9705 - val_loss: 1.9938 - val_accuracy: 0.6493\n",
            "Epoch 221/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.9726 - val_loss: 2.0173 - val_accuracy: 0.6588\n",
            "Epoch 222/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 0.9757 - val_loss: 2.0533 - val_accuracy: 0.6493\n",
            "Epoch 223/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9692 - val_loss: 2.1137 - val_accuracy: 0.6635\n",
            "Epoch 224/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.9591 - val_loss: 2.0694 - val_accuracy: 0.6540\n",
            "Epoch 225/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9732 - val_loss: 2.1244 - val_accuracy: 0.6540\n",
            "Epoch 226/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.9708 - val_loss: 2.1395 - val_accuracy: 0.6398\n",
            "Epoch 227/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.9553 - val_loss: 1.9240 - val_accuracy: 0.6114\n",
            "Epoch 228/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8862 - val_loss: 1.9580 - val_accuracy: 0.6398\n",
            "Epoch 229/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.2287 - accuracy: 0.9082 - val_loss: 2.1423 - val_accuracy: 0.6445\n",
            "Epoch 230/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9470 - val_loss: 2.3244 - val_accuracy: 0.6019\n",
            "Epoch 231/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.2045 - accuracy: 0.9301 - val_loss: 2.1683 - val_accuracy: 0.6209\n",
            "Epoch 232/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9430 - val_loss: 2.1208 - val_accuracy: 0.6445\n",
            "Epoch 233/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9587 - val_loss: 1.9300 - val_accuracy: 0.6635\n",
            "Epoch 234/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0832 - accuracy: 0.9699 - val_loss: 2.0354 - val_accuracy: 0.6588\n",
            "Epoch 235/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9738 - val_loss: 2.0185 - val_accuracy: 0.6635\n",
            "Epoch 236/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.9645 - val_loss: 2.0436 - val_accuracy: 0.6493\n",
            "Epoch 237/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9736 - val_loss: 2.0304 - val_accuracy: 0.6682\n",
            "Epoch 238/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9743 - val_loss: 1.9984 - val_accuracy: 0.6635\n",
            "Epoch 239/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0792 - accuracy: 0.9654 - val_loss: 2.0014 - val_accuracy: 0.6682\n",
            "Epoch 240/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0745 - accuracy: 0.9672 - val_loss: 2.0725 - val_accuracy: 0.6493\n",
            "Epoch 241/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9623 - val_loss: 2.0575 - val_accuracy: 0.6635\n",
            "Epoch 242/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9672 - val_loss: 2.0618 - val_accuracy: 0.6445\n",
            "Epoch 243/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9665 - val_loss: 2.0986 - val_accuracy: 0.6540\n",
            "Epoch 244/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.9629 - val_loss: 2.0492 - val_accuracy: 0.6588\n",
            "Epoch 245/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0861 - accuracy: 0.9640 - val_loss: 2.0907 - val_accuracy: 0.6540\n",
            "Epoch 246/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.9603 - val_loss: 2.1178 - val_accuracy: 0.6493\n",
            "Epoch 247/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9339 - val_loss: 2.0304 - val_accuracy: 0.5782\n",
            "Epoch 248/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.8421 - val_loss: 1.8023 - val_accuracy: 0.6398\n",
            "Epoch 249/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.3117 - accuracy: 0.8866 - val_loss: 1.7924 - val_accuracy: 0.6493\n",
            "Epoch 250/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1974 - accuracy: 0.9261 - val_loss: 1.8747 - val_accuracy: 0.6777\n",
            "Epoch 251/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.9550 - val_loss: 1.8025 - val_accuracy: 0.6493\n",
            "Epoch 252/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.9620 - val_loss: 1.8365 - val_accuracy: 0.6540\n",
            "Epoch 253/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0835 - accuracy: 0.9649 - val_loss: 2.1110 - val_accuracy: 0.6398\n",
            "Epoch 254/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9652 - val_loss: 1.8374 - val_accuracy: 0.6730\n",
            "Epoch 255/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1217 - accuracy: 0.9539 - val_loss: 2.2818 - val_accuracy: 0.6445\n",
            "Epoch 256/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.2359 - accuracy: 0.9159 - val_loss: 2.0256 - val_accuracy: 0.6256\n",
            "Epoch 257/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.9108 - val_loss: 1.8369 - val_accuracy: 0.6682\n",
            "Epoch 258/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1240 - accuracy: 0.9485 - val_loss: 2.0762 - val_accuracy: 0.6493\n",
            "Epoch 259/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9655 - val_loss: 2.0597 - val_accuracy: 0.6682\n",
            "Epoch 260/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.9704 - val_loss: 2.0938 - val_accuracy: 0.6445\n",
            "Epoch 261/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.9687 - val_loss: 2.0875 - val_accuracy: 0.6540\n",
            "Epoch 262/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0749 - accuracy: 0.9666 - val_loss: 2.0293 - val_accuracy: 0.6493\n",
            "Epoch 263/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0727 - accuracy: 0.9688 - val_loss: 2.0683 - val_accuracy: 0.6540\n",
            "Epoch 264/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0662 - accuracy: 0.9755 - val_loss: 2.0544 - val_accuracy: 0.6588\n",
            "Epoch 265/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0663 - accuracy: 0.9732 - val_loss: 2.0863 - val_accuracy: 0.6540\n",
            "Epoch 266/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9672 - val_loss: 2.1245 - val_accuracy: 0.6588\n",
            "Epoch 267/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9763 - val_loss: 2.0789 - val_accuracy: 0.6540\n",
            "Epoch 268/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.9724 - val_loss: 2.0307 - val_accuracy: 0.6445\n",
            "Epoch 269/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9715 - val_loss: 2.1427 - val_accuracy: 0.6445\n",
            "Epoch 270/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9692 - val_loss: 2.1361 - val_accuracy: 0.6682\n",
            "Epoch 271/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.2537 - accuracy: 0.9243 - val_loss: 2.0059 - val_accuracy: 0.5545\n",
            "Epoch 272/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.8053 - accuracy: 0.7479 - val_loss: 1.6022 - val_accuracy: 0.6066\n",
            "Epoch 273/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8521 - val_loss: 1.6150 - val_accuracy: 0.6066\n",
            "Epoch 274/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.2842 - accuracy: 0.8919 - val_loss: 1.9295 - val_accuracy: 0.5972\n",
            "Epoch 275/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9493 - val_loss: 2.0014 - val_accuracy: 0.6161\n",
            "Epoch 276/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.9299 - val_loss: 2.0150 - val_accuracy: 0.6398\n",
            "Epoch 277/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.2063 - accuracy: 0.9251 - val_loss: 2.0771 - val_accuracy: 0.6445\n",
            "Epoch 278/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9246 - val_loss: 2.0091 - val_accuracy: 0.6351\n",
            "Epoch 279/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.9337 - val_loss: 1.9361 - val_accuracy: 0.6445\n",
            "Epoch 280/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.9333 - val_loss: 1.9439 - val_accuracy: 0.6351\n",
            "Epoch 281/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.9573 - val_loss: 2.0371 - val_accuracy: 0.6398\n",
            "Epoch 282/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1110 - accuracy: 0.9558 - val_loss: 1.9711 - val_accuracy: 0.6445\n",
            "Epoch 283/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 0.9680 - val_loss: 1.9714 - val_accuracy: 0.6540\n",
            "Epoch 284/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9627 - val_loss: 2.0148 - val_accuracy: 0.6540\n",
            "Epoch 285/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.9712 - val_loss: 1.9790 - val_accuracy: 0.6351\n",
            "Epoch 286/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1087 - accuracy: 0.9599 - val_loss: 2.2193 - val_accuracy: 0.6540\n",
            "Epoch 287/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9459 - val_loss: 2.4534 - val_accuracy: 0.5972\n",
            "Epoch 288/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8917 - val_loss: 1.8717 - val_accuracy: 0.6114\n",
            "Epoch 289/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.9034 - val_loss: 2.2096 - val_accuracy: 0.6114\n",
            "Epoch 290/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1258 - accuracy: 0.9526 - val_loss: 2.1724 - val_accuracy: 0.6209\n",
            "Epoch 291/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 0.9555 - val_loss: 2.1014 - val_accuracy: 0.6303\n",
            "Epoch 292/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.9713 - val_loss: 2.1000 - val_accuracy: 0.6351\n",
            "Epoch 293/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0984 - accuracy: 0.9606 - val_loss: 2.0390 - val_accuracy: 0.6445\n",
            "Epoch 294/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0889 - accuracy: 0.9662 - val_loss: 2.0441 - val_accuracy: 0.6588\n",
            "Epoch 295/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.9647 - val_loss: 1.9752 - val_accuracy: 0.6445\n",
            "Epoch 296/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1316 - accuracy: 0.9485 - val_loss: 2.4958 - val_accuracy: 0.5972\n",
            "Epoch 297/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9175 - val_loss: 2.0716 - val_accuracy: 0.6445\n",
            "Epoch 298/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.9209 - val_loss: 2.5034 - val_accuracy: 0.6019\n",
            "Epoch 299/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.3093 - accuracy: 0.8921 - val_loss: 2.3799 - val_accuracy: 0.6066\n",
            "Epoch 300/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.9412 - val_loss: 2.0412 - val_accuracy: 0.6209\n",
            "Epoch 301/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.9647 - val_loss: 2.0330 - val_accuracy: 0.6682\n",
            "Epoch 302/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9509 - val_loss: 2.1132 - val_accuracy: 0.6303\n",
            "Epoch 303/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9694 - val_loss: 2.1427 - val_accuracy: 0.6445\n",
            "Epoch 304/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9639 - val_loss: 2.1894 - val_accuracy: 0.6445\n",
            "Epoch 305/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0856 - accuracy: 0.9681 - val_loss: 2.3175 - val_accuracy: 0.6209\n",
            "Epoch 306/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8607 - val_loss: 2.2882 - val_accuracy: 0.5972\n",
            "Epoch 307/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9126 - val_loss: 2.2613 - val_accuracy: 0.6256\n",
            "Epoch 308/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9521 - val_loss: 2.1045 - val_accuracy: 0.6209\n",
            "Epoch 309/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.9608 - val_loss: 2.2647 - val_accuracy: 0.6209\n",
            "Epoch 310/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9668 - val_loss: 2.1563 - val_accuracy: 0.6445\n",
            "Epoch 311/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9748 - val_loss: 2.0861 - val_accuracy: 0.6398\n",
            "Epoch 312/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.9674 - val_loss: 2.0923 - val_accuracy: 0.6445\n",
            "Epoch 313/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.9692 - val_loss: 2.1176 - val_accuracy: 0.6209\n",
            "Epoch 314/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0878 - accuracy: 0.9620 - val_loss: 2.1451 - val_accuracy: 0.6445\n",
            "Epoch 315/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.9499 - val_loss: 2.0844 - val_accuracy: 0.6209\n",
            "Epoch 316/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8866 - val_loss: 2.3324 - val_accuracy: 0.6019\n",
            "Epoch 317/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.9106 - val_loss: 2.0890 - val_accuracy: 0.6303\n",
            "Epoch 318/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.9460 - val_loss: 2.1773 - val_accuracy: 0.6588\n",
            "Epoch 319/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9466 - val_loss: 2.0863 - val_accuracy: 0.6209\n",
            "Epoch 320/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9660 - val_loss: 2.0375 - val_accuracy: 0.6493\n",
            "Epoch 321/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.9707 - val_loss: 1.9876 - val_accuracy: 0.6445\n",
            "Epoch 322/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.9676 - val_loss: 2.0377 - val_accuracy: 0.6398\n",
            "Epoch 323/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9684 - val_loss: 2.0130 - val_accuracy: 0.6303\n",
            "Epoch 324/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9727 - val_loss: 2.1102 - val_accuracy: 0.6493\n",
            "Epoch 325/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9653 - val_loss: 2.1062 - val_accuracy: 0.6209\n",
            "Epoch 326/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9527 - val_loss: 2.3296 - val_accuracy: 0.5924\n",
            "Epoch 327/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.9074 - val_loss: 2.0585 - val_accuracy: 0.6114\n",
            "Epoch 328/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9176 - val_loss: 2.0025 - val_accuracy: 0.6445\n",
            "Epoch 329/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9405 - val_loss: 2.1551 - val_accuracy: 0.6114\n",
            "Epoch 330/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9507 - val_loss: 2.1601 - val_accuracy: 0.6209\n",
            "Epoch 331/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9526 - val_loss: 2.3184 - val_accuracy: 0.6209\n",
            "Epoch 332/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1219 - accuracy: 0.9586 - val_loss: 2.2574 - val_accuracy: 0.6540\n",
            "Epoch 333/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9396 - val_loss: 2.1523 - val_accuracy: 0.5829\n",
            "Epoch 334/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.9097 - val_loss: 1.9704 - val_accuracy: 0.6730\n",
            "Epoch 335/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9097 - val_loss: 2.2234 - val_accuracy: 0.6303\n",
            "Epoch 336/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.9252 - val_loss: 2.0669 - val_accuracy: 0.6256\n",
            "Epoch 337/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9701 - val_loss: 2.1036 - val_accuracy: 0.6351\n",
            "Epoch 338/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0868 - accuracy: 0.9693 - val_loss: 2.1340 - val_accuracy: 0.6351\n",
            "Epoch 339/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9725 - val_loss: 2.1403 - val_accuracy: 0.6303\n",
            "Epoch 340/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9726 - val_loss: 2.2380 - val_accuracy: 0.6256\n",
            "Epoch 341/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.9715 - val_loss: 2.1572 - val_accuracy: 0.6256\n",
            "Epoch 342/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9584 - val_loss: 2.1047 - val_accuracy: 0.6351\n",
            "Epoch 343/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 0.9707 - val_loss: 2.2069 - val_accuracy: 0.6209\n",
            "Epoch 344/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.9686 - val_loss: 2.2079 - val_accuracy: 0.6256\n",
            "Epoch 345/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.9622 - val_loss: 2.1692 - val_accuracy: 0.6540\n",
            "Epoch 346/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.9622 - val_loss: 2.1827 - val_accuracy: 0.6398\n",
            "Epoch 347/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0975 - accuracy: 0.9650 - val_loss: 2.2256 - val_accuracy: 0.6256\n",
            "Epoch 348/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9721 - val_loss: 2.2272 - val_accuracy: 0.6303\n",
            "Epoch 349/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9621 - val_loss: 2.0697 - val_accuracy: 0.6351\n",
            "Epoch 350/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.8058 - val_loss: 1.9765 - val_accuracy: 0.6066\n",
            "Epoch 351/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8709 - val_loss: 2.0548 - val_accuracy: 0.5877\n",
            "Epoch 352/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9488 - val_loss: 2.0931 - val_accuracy: 0.6019\n",
            "Epoch 353/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.9565 - val_loss: 2.2029 - val_accuracy: 0.6588\n",
            "Epoch 354/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9452 - val_loss: 2.0257 - val_accuracy: 0.6730\n",
            "Epoch 355/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9730 - val_loss: 2.0978 - val_accuracy: 0.6398\n",
            "Epoch 356/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9711 - val_loss: 2.1311 - val_accuracy: 0.6588\n",
            "Epoch 357/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.9670 - val_loss: 2.1458 - val_accuracy: 0.6540\n",
            "Epoch 358/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9696 - val_loss: 2.1364 - val_accuracy: 0.6540\n",
            "Epoch 359/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.9707 - val_loss: 2.1295 - val_accuracy: 0.6445\n",
            "Epoch 360/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 0.9706 - val_loss: 2.0897 - val_accuracy: 0.6588\n",
            "Epoch 361/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9705 - val_loss: 2.0890 - val_accuracy: 0.6540\n",
            "Epoch 362/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0722 - accuracy: 0.9727 - val_loss: 2.0822 - val_accuracy: 0.6588\n",
            "Epoch 363/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9246 - val_loss: 2.4050 - val_accuracy: 0.5735\n",
            "Epoch 364/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.8297 - val_loss: 1.9874 - val_accuracy: 0.6161\n",
            "Epoch 365/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.2564 - accuracy: 0.9064 - val_loss: 1.9929 - val_accuracy: 0.6256\n",
            "Epoch 366/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1317 - accuracy: 0.9501 - val_loss: 2.2299 - val_accuracy: 0.6019\n",
            "Epoch 367/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1134 - accuracy: 0.9501 - val_loss: 2.0783 - val_accuracy: 0.6682\n",
            "Epoch 368/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9664 - val_loss: 2.0659 - val_accuracy: 0.6540\n",
            "Epoch 369/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0817 - accuracy: 0.9690 - val_loss: 2.1185 - val_accuracy: 0.6540\n",
            "Epoch 370/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0776 - accuracy: 0.9669 - val_loss: 2.0793 - val_accuracy: 0.6588\n",
            "Epoch 371/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9698 - val_loss: 2.1851 - val_accuracy: 0.6398\n",
            "Epoch 372/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9770 - val_loss: 2.1044 - val_accuracy: 0.6588\n",
            "Epoch 373/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9722 - val_loss: 2.1474 - val_accuracy: 0.6351\n",
            "Epoch 374/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9633 - val_loss: 2.1110 - val_accuracy: 0.6445\n",
            "Epoch 375/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9690 - val_loss: 2.1560 - val_accuracy: 0.6445\n",
            "Epoch 376/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9671 - val_loss: 2.1452 - val_accuracy: 0.6682\n",
            "Epoch 377/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 0.9712 - val_loss: 2.1460 - val_accuracy: 0.6445\n",
            "Epoch 378/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.9662 - val_loss: 2.1434 - val_accuracy: 0.6303\n",
            "Epoch 379/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0781 - accuracy: 0.9679 - val_loss: 2.1315 - val_accuracy: 0.6398\n",
            "Epoch 380/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0868 - accuracy: 0.9630 - val_loss: 2.2765 - val_accuracy: 0.6161\n",
            "Epoch 381/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.2196 - accuracy: 0.9220 - val_loss: 2.1309 - val_accuracy: 0.5877\n",
            "Epoch 382/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.7678 - val_loss: 1.8591 - val_accuracy: 0.6303\n",
            "Epoch 383/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8618 - val_loss: 1.8334 - val_accuracy: 0.6493\n",
            "Epoch 384/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2837 - accuracy: 0.9019 - val_loss: 1.8634 - val_accuracy: 0.6303\n",
            "Epoch 385/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9388 - val_loss: 2.0201 - val_accuracy: 0.6114\n",
            "Epoch 386/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9233 - val_loss: 2.1724 - val_accuracy: 0.6209\n",
            "Epoch 387/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.9226 - val_loss: 2.2181 - val_accuracy: 0.6351\n",
            "Epoch 388/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 0.9501 - val_loss: 2.3163 - val_accuracy: 0.6209\n",
            "Epoch 389/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9302 - val_loss: 2.2586 - val_accuracy: 0.6398\n",
            "Epoch 390/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9552 - val_loss: 2.1100 - val_accuracy: 0.6398\n",
            "Epoch 391/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.9640 - val_loss: 2.1824 - val_accuracy: 0.6303\n",
            "Epoch 392/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9734 - val_loss: 2.1727 - val_accuracy: 0.6114\n",
            "Epoch 393/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0804 - accuracy: 0.9686 - val_loss: 2.2079 - val_accuracy: 0.6161\n",
            "Epoch 394/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 0.9744 - val_loss: 2.2411 - val_accuracy: 0.6398\n",
            "Epoch 395/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.9750 - val_loss: 2.2654 - val_accuracy: 0.6209\n",
            "Epoch 396/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9754 - val_loss: 2.2365 - val_accuracy: 0.6303\n",
            "Epoch 397/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9732 - val_loss: 2.2322 - val_accuracy: 0.6256\n",
            "Epoch 398/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.9755 - val_loss: 2.2819 - val_accuracy: 0.6209\n",
            "Epoch 399/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.9668 - val_loss: 2.2849 - val_accuracy: 0.6209\n",
            "Epoch 400/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0794 - accuracy: 0.9668 - val_loss: 2.2292 - val_accuracy: 0.6445\n",
            "Epoch 401/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9711 - val_loss: 2.3215 - val_accuracy: 0.6209\n",
            "Epoch 402/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.9727 - val_loss: 2.3338 - val_accuracy: 0.6303\n",
            "Epoch 403/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9655 - val_loss: 2.3152 - val_accuracy: 0.6161\n",
            "Epoch 404/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0749 - accuracy: 0.9664 - val_loss: 2.3486 - val_accuracy: 0.6398\n",
            "Epoch 405/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0794 - accuracy: 0.9702 - val_loss: 2.5440 - val_accuracy: 0.6256\n",
            "Epoch 406/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.6403 - accuracy: 0.8134 - val_loss: 1.7560 - val_accuracy: 0.6114\n",
            "Epoch 407/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.4113 - accuracy: 0.8616 - val_loss: 1.7916 - val_accuracy: 0.6209\n",
            "Epoch 408/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8826 - val_loss: 1.8644 - val_accuracy: 0.6161\n",
            "Epoch 409/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9205 - val_loss: 2.1223 - val_accuracy: 0.6493\n",
            "Epoch 410/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1741 - accuracy: 0.9306 - val_loss: 2.0356 - val_accuracy: 0.6351\n",
            "Epoch 411/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1287 - accuracy: 0.9494 - val_loss: 2.1669 - val_accuracy: 0.6398\n",
            "Epoch 412/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.9455 - val_loss: 2.1153 - val_accuracy: 0.6303\n",
            "Epoch 413/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9544 - val_loss: 2.1111 - val_accuracy: 0.6114\n",
            "Epoch 414/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9589 - val_loss: 1.9696 - val_accuracy: 0.6445\n",
            "Epoch 415/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.9236 - val_loss: 2.1351 - val_accuracy: 0.5972\n",
            "Epoch 416/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.9271 - val_loss: 2.1420 - val_accuracy: 0.6161\n",
            "Epoch 417/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.9101 - val_loss: 2.0385 - val_accuracy: 0.6256\n",
            "Epoch 418/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.2847 - accuracy: 0.9018 - val_loss: 2.1039 - val_accuracy: 0.6114\n",
            "Epoch 419/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9277 - val_loss: 2.0789 - val_accuracy: 0.6114\n",
            "Epoch 420/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.9555 - val_loss: 2.1526 - val_accuracy: 0.6114\n",
            "Epoch 421/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.9596 - val_loss: 2.1782 - val_accuracy: 0.6256\n",
            "Epoch 422/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.9638 - val_loss: 2.0406 - val_accuracy: 0.6351\n",
            "Epoch 423/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9762 - val_loss: 2.0381 - val_accuracy: 0.6351\n",
            "Epoch 424/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9660 - val_loss: 2.0565 - val_accuracy: 0.6540\n",
            "Epoch 425/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9677 - val_loss: 2.0887 - val_accuracy: 0.6588\n",
            "Epoch 426/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.9657 - val_loss: 2.3130 - val_accuracy: 0.6161\n",
            "Epoch 427/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1151 - accuracy: 0.9557 - val_loss: 2.0367 - val_accuracy: 0.6445\n",
            "Epoch 428/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9331 - val_loss: 2.0414 - val_accuracy: 0.6398\n",
            "Epoch 429/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.8978 - val_loss: 2.2851 - val_accuracy: 0.6066\n",
            "Epoch 430/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9135 - val_loss: 1.9169 - val_accuracy: 0.6398\n",
            "Epoch 431/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.9045 - val_loss: 2.0428 - val_accuracy: 0.6303\n",
            "Epoch 432/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0938 - accuracy: 0.9679 - val_loss: 2.0340 - val_accuracy: 0.6398\n",
            "Epoch 433/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9692 - val_loss: 2.0868 - val_accuracy: 0.6351\n",
            "Epoch 434/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9698 - val_loss: 2.1101 - val_accuracy: 0.6398\n",
            "Epoch 435/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.9708 - val_loss: 2.1551 - val_accuracy: 0.6303\n",
            "Epoch 436/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.9706 - val_loss: 2.1554 - val_accuracy: 0.6256\n",
            "Epoch 437/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9752 - val_loss: 2.1219 - val_accuracy: 0.6256\n",
            "Epoch 438/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9658 - val_loss: 2.1730 - val_accuracy: 0.6351\n",
            "Epoch 439/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.9612 - val_loss: 2.1717 - val_accuracy: 0.6493\n",
            "Epoch 440/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0726 - accuracy: 0.9784 - val_loss: 2.1485 - val_accuracy: 0.6445\n",
            "Epoch 441/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.9705 - val_loss: 2.0640 - val_accuracy: 0.6351\n",
            "Epoch 442/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 0.9700 - val_loss: 2.3855 - val_accuracy: 0.6209\n",
            "Epoch 443/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.8615 - val_loss: 2.5311 - val_accuracy: 0.5735\n",
            "Epoch 444/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8651 - val_loss: 2.1481 - val_accuracy: 0.6114\n",
            "Epoch 445/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9267 - val_loss: 2.2204 - val_accuracy: 0.6303\n",
            "Epoch 446/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.9295 - val_loss: 2.2146 - val_accuracy: 0.6019\n",
            "Epoch 447/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1771 - accuracy: 0.9350 - val_loss: 2.2332 - val_accuracy: 0.6114\n",
            "Epoch 448/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.9622 - val_loss: 2.1943 - val_accuracy: 0.6209\n",
            "Epoch 449/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9690 - val_loss: 2.1203 - val_accuracy: 0.6209\n",
            "Epoch 450/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.9617 - val_loss: 2.1275 - val_accuracy: 0.6256\n",
            "Epoch 451/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.9602 - val_loss: 2.1413 - val_accuracy: 0.6351\n",
            "Epoch 452/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9653 - val_loss: 2.1188 - val_accuracy: 0.6398\n",
            "Epoch 453/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9665 - val_loss: 2.1960 - val_accuracy: 0.6114\n",
            "Epoch 454/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1026 - accuracy: 0.9567 - val_loss: 2.1361 - val_accuracy: 0.6303\n",
            "Epoch 455/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9605 - val_loss: 2.1476 - val_accuracy: 0.6493\n",
            "Epoch 456/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9710 - val_loss: 2.2358 - val_accuracy: 0.6445\n",
            "Epoch 457/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9761 - val_loss: 2.1962 - val_accuracy: 0.6209\n",
            "Epoch 458/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9739 - val_loss: 2.2045 - val_accuracy: 0.6540\n",
            "Epoch 459/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9704 - val_loss: 2.2305 - val_accuracy: 0.6445\n",
            "Epoch 460/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.9733 - val_loss: 2.2624 - val_accuracy: 0.6303\n",
            "Epoch 461/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9622 - val_loss: 2.2228 - val_accuracy: 0.6303\n",
            "Epoch 462/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9704 - val_loss: 2.2375 - val_accuracy: 0.6066\n",
            "Epoch 463/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.9659 - val_loss: 2.2404 - val_accuracy: 0.6540\n",
            "Epoch 464/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.8460 - val_loss: 1.7406 - val_accuracy: 0.5640\n",
            "Epoch 465/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8385 - val_loss: 2.0471 - val_accuracy: 0.6256\n",
            "Epoch 466/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8589 - val_loss: 2.0402 - val_accuracy: 0.5972\n",
            "Epoch 467/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.8982 - val_loss: 2.1906 - val_accuracy: 0.6114\n",
            "Epoch 468/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.9194 - val_loss: 2.1708 - val_accuracy: 0.5829\n",
            "Epoch 469/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8747 - val_loss: 1.8336 - val_accuracy: 0.6540\n",
            "Epoch 470/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.9180 - val_loss: 2.0353 - val_accuracy: 0.6540\n",
            "Epoch 471/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1662 - accuracy: 0.9433 - val_loss: 2.1048 - val_accuracy: 0.6256\n",
            "Epoch 472/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1772 - accuracy: 0.9356 - val_loss: 2.2941 - val_accuracy: 0.6209\n",
            "Epoch 473/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1667 - accuracy: 0.9355 - val_loss: 2.1651 - val_accuracy: 0.6209\n",
            "Epoch 474/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9362 - val_loss: 2.1609 - val_accuracy: 0.6303\n",
            "Epoch 475/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9319 - val_loss: 1.9339 - val_accuracy: 0.6398\n",
            "Epoch 476/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1336 - accuracy: 0.9535 - val_loss: 2.1674 - val_accuracy: 0.6161\n",
            "Epoch 477/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9573 - val_loss: 2.1677 - val_accuracy: 0.6066\n",
            "Epoch 478/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0760 - accuracy: 0.9716 - val_loss: 2.2300 - val_accuracy: 0.6066\n",
            "Epoch 479/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9699 - val_loss: 2.2796 - val_accuracy: 0.6303\n",
            "Epoch 480/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.9609 - val_loss: 2.3017 - val_accuracy: 0.6019\n",
            "Epoch 481/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0857 - accuracy: 0.9669 - val_loss: 2.2809 - val_accuracy: 0.6209\n",
            "Epoch 482/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9568 - val_loss: 2.1866 - val_accuracy: 0.6019\n",
            "Epoch 483/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.9418 - val_loss: 2.1176 - val_accuracy: 0.6209\n",
            "Epoch 484/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.0889 - accuracy: 0.9706 - val_loss: 2.4097 - val_accuracy: 0.6114\n",
            "Epoch 485/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.9561 - val_loss: 2.2035 - val_accuracy: 0.6114\n",
            "Epoch 486/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8692 - val_loss: 2.2234 - val_accuracy: 0.5782\n",
            "Epoch 487/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9138 - val_loss: 2.0018 - val_accuracy: 0.6066\n",
            "Epoch 488/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.2589 - accuracy: 0.9110 - val_loss: 2.0973 - val_accuracy: 0.5782\n",
            "Epoch 489/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.9345 - val_loss: 2.2674 - val_accuracy: 0.6019\n",
            "Epoch 490/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9251 - val_loss: 1.9248 - val_accuracy: 0.6303\n",
            "Epoch 491/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.9059 - val_loss: 2.3380 - val_accuracy: 0.5877\n",
            "Epoch 492/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9526 - val_loss: 2.1362 - val_accuracy: 0.6351\n",
            "Epoch 493/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.9571 - val_loss: 2.1840 - val_accuracy: 0.6161\n",
            "Epoch 494/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.9566 - val_loss: 2.2008 - val_accuracy: 0.6114\n",
            "Epoch 495/500\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.9615 - val_loss: 2.2820 - val_accuracy: 0.6019\n",
            "Epoch 496/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9242 - val_loss: 2.3155 - val_accuracy: 0.6019\n",
            "Epoch 497/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.9539 - val_loss: 2.1886 - val_accuracy: 0.6493\n",
            "Epoch 498/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1126 - accuracy: 0.9583 - val_loss: 2.1149 - val_accuracy: 0.6066\n",
            "Epoch 499/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.9594 - val_loss: 2.1773 - val_accuracy: 0.5924\n",
            "Epoch 500/500\n",
            "119/119 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9668 - val_loss: 2.0478 - val_accuracy: 0.6303\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x2b88eea4cd0>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics='accuracy')\n",
        "model.fit(X_train, y_train, validation_split=0.1, batch_size=16, epochs=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmTz5Ejg_lWx",
        "outputId": "e050fb64-12c4-4926-8a66-e2291e7fd230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on the test data\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 2.4268 - accuracy: 0.6350\n",
            "test loss, test acc: [2.4267871379852295, 0.6349809765815735]\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluating on the test data\")\n",
        "results = model.evaluate(X_test, y_test, batch_size=20)\n",
        "print(\"test loss, test acc:\", results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxjHLbbt_lWx"
      },
      "source": [
        "### Seems like our model doesn't really improve, and get's stuch around the 64% mark. We'll try a CNN network which are known to work with Speech recognision problems:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5qp2YJ1_lWx"
      },
      "source": [
        "### First we'll add another dimension to our data in order for it to fit the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzeMGT_E_lWx"
      },
      "outputs": [],
      "source": [
        "x_train_new = np.expand_dims(X_train, axis=2)\n",
        "x_test_new = np.expand_dims(X_test, axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWJf1rxD_lWx",
        "outputId": "c4bef866-aa0e-4e1e-e081-5486a9953657"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2102, 40, 1), (526, 40, 1))"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train_new.shape, x_test_new.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_RPoK1Z_lWx"
      },
      "outputs": [],
      "source": [
        "model2 = Sequential(\n",
        "    [\n",
        "     layers.Conv1D(128, 3, activation='relu', input_shape=(40,1)),\n",
        "     layers.MaxPooling1D(),\n",
        "     layers.Conv1D(128, 3, activation='relu'),\n",
        "     layers.MaxPooling1D(),\n",
        "     layers.Conv1D(128, 3, activation='relu'),\n",
        "     layers.MaxPooling1D(),\n",
        "     layers.Flatten(),\n",
        "     layers.Dense(64, activation=\"relu\"),\n",
        "     layers.Dense(8, activation=\"softmax\")\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3wGNCUk_lWy",
        "outputId": "7aa5ef7d-6ef2-4d19-9f0b-6b3547b996a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((None, 40, 1), TensorShape([None, 8]))"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.input_shape, model2.output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yGn2wK-_lWy",
        "outputId": "7160782f-6790-4dae-f6b5-c9d80e35b875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_22 (Conv1D)           (None, 38, 128)           512       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 19, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_23 (Conv1D)           (None, 17, 128)           49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling (None, 8, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_24 (Conv1D)           (None, 6, 128)            49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling (None, 3, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten_19 (Flatten)         (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 64)                24640     \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 8)                 520       \n",
            "=================================================================\n",
            "Total params: 124,232\n",
            "Trainable params: 124,232\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvFoXl5n_lWy",
        "outputId": "462f62a1-cbbd-4ef4-b1c3-cf1b19feb071"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "119/119 [==============================] - 1s 7ms/step - loss: 0.1209 - accuracy: 0.9524 - val_loss: 1.9974 - val_accuracy: 0.6635\n",
            "Epoch 2/10\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 0.1593 - accuracy: 0.9325 - val_loss: 1.8278 - val_accuracy: 0.6777\n",
            "Epoch 3/10\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 0.2298 - accuracy: 0.9258 - val_loss: 1.7046 - val_accuracy: 0.6588\n",
            "Epoch 4/10\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 0.0818 - accuracy: 0.9688 - val_loss: 1.8895 - val_accuracy: 0.6825\n",
            "Epoch 5/10\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 0.0806 - accuracy: 0.9666 - val_loss: 1.7779 - val_accuracy: 0.7156\n",
            "Epoch 6/10\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 0.0807 - accuracy: 0.9649 - val_loss: 1.7603 - val_accuracy: 0.7156\n",
            "Epoch 7/10\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 0.0647 - accuracy: 0.9711 - val_loss: 1.7878 - val_accuracy: 0.7109\n",
            "Epoch 8/10\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 0.0730 - accuracy: 0.9694 - val_loss: 1.8292 - val_accuracy: 0.7014\n",
            "Epoch 9/10\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 0.0646 - accuracy: 0.9736 - val_loss: 1.8240 - val_accuracy: 0.7156\n",
            "Epoch 10/10\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 0.0869 - accuracy: 0.9631 - val_loss: 1.8276 - val_accuracy: 0.7062\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x2b88ed46070>"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics='accuracy')\n",
        "model2.fit(x_train_new, y_train, validation_split=0.1, batch_size=16, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPfiYDRA_lWy",
        "outputId": "c57b5271-e075-48ff-f949-b0e661369bc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on the test data\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.8146 - accuracy: 0.6958\n",
            "test loss, test acc: [1.8145948648452759, 0.6958174705505371]\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluating on the test data\")\n",
        "results = model2.evaluate(x_test_new, y_test, batch_size=100)\n",
        "print(\"test loss, test acc:\", results)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}